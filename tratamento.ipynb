{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)\n",
    "data=pd.read_csv('train.csv') # dataset do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dtypes\n",
    "data.info() #milage\n",
    "# data.head()\n",
    "# data.tail()\n",
    "# data.shape #(3207, 12)\n",
    "# data.nunique() # valores unicos para cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo mais antigo e mais novo:\n",
    "antigo=data['model_year'].min()\n",
    "novo=data['model_year'].max()\n",
    "print(antigo,novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correção: 'milage' -> INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#milage:\n",
    "valores_corrigidos=[]\n",
    "for milage in data['milage']: # para cada quilometragem do dataset\n",
    "    separa=re.split(r'[ ]',milage) # sepagar o numero do mi\n",
    "    numero=separa[0] # numero\n",
    "    letra=separa[1] # mi\n",
    "    verifica=re.search(r'^[0-9]+[,]?[0-9]+$',numero) # verifica se o numeros sao sempre iguais(com casas decimais ou não)\n",
    "    verifica2=re.search(r'^mi\\.$',letra) # verifica se a letra é sempre mi\n",
    "    if verifica and verifica2: # se seguir o padra numero + mi:\n",
    "        numero=int(re.sub(r',','',numero)) # retira a , dos numeros e passa para inteiro ( estavam em obj)\n",
    "        valores_corrigidos.append(numero)\n",
    "    else: \n",
    "        print(milage,False) # tem dados diferentes no dataset\n",
    "\n",
    "data['milage']=valores_corrigidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificaçao\n",
    "for m in data['milage']:\n",
    "    if not isinstance(m, (int)):\n",
    "        print('dado incorreto')\n",
    "# tudo certo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NULL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fuel_type'].value_counts() # –  38 ( existem 38 linhas com (-) -> nao se sabe)\n",
    "data['accident'].value_counts()\n",
    "data['clean_title'].value_counts() # Yes -> 2740, os restantes são valores nulos (nan)\n",
    "# data['clean_title'].unique()\n",
    "# verificar outros tipos de dizer valores nulos: ( como (-) por exemplo)\n",
    "data['brand'].value_counts() # tudo certo\n",
    "data['model'].nunique() # tudo certo\n",
    "data['model_year'].value_counts() # tudo certo\n",
    "data['engine'].value_counts() # – 38 -> nao se sabe\n",
    "data['transmission'].value_counts() # 4 -> nao se sabe \n",
    "data['ext_col'].value_counts()# 11 -> nao se sabe\n",
    "data['int_col'].value_counts() # 98 -> nao se sabe\n",
    "for preco in data['price']: # tudo certo\n",
    "    if not isinstance(preco, int):\n",
    "        print('erro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['milage'])\n",
    "# len(data['milage'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> nº de velocidades na transmissão existentes no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=list(data['transmission'].unique())\n",
    "alls = [int(numero) for string in d2 for numero in re.findall(r'\\d+', string)]\n",
    "list(set(alls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verificar significado de '-' e NaN para o tipo de combustível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.loc[data['fuel_type'] == '–'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['fuel_type'] == '–') & (data['engine'] != '–')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### OS CARROS PARA OS QUAIS O FUEL_TYPE É '-' NÃO INDICADO, TAMBÉM NÃO SE CONHECE A CONFIGURAÇÃO DO MOTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAR QUE OS CARROS COM NAN NO TIPO DE COMBUSTÍVEL SÃO CARROS ELÉTRICOS\n",
    "elec=data[data['fuel_type'].isnull()]\n",
    "pattern = re.compile(r'\\bElectric\\b', flags=re.IGNORECASE)\n",
    "contains_electric = elec['engine'].str.contains(pattern, na=False)\n",
    "# Selecionar todas as linhas que não contêm 'Electric' na coluna 'engine'\n",
    "elec[~contains_electric]\n",
    "# elec[contains_electric].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### os carros com NaN para 'fuel_type' são carros elétricos\n",
    "Tesla --> elétrico\n",
    "Standard Range Battery --> elétrico\n",
    "111.2Ah / FR 70kW / RR 160kW (697V) --> especificidade de baterias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='box',figsize=(15,6),subplots=True) # grafico do codigo acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['model_year']<1990] # outlier do 1º gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['milage']>350000] # outlier do 2º gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['price']>1500000] # outlier 3º gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BARPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que 'data' seja seu DataFrame com colunas de atributos e 'preco'\n",
    "# Vamos calcular a média do preço para cada atributo (exceto a última coluna)\n",
    "data['fuel_type'].fillna('Elétrico', inplace=True)\n",
    "\n",
    "# Lista para armazenar os gráficos gerados\n",
    "colunas = ['brand', 'model', 'model_year', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
    "num_linhas = 3\n",
    "num_colunas = 3\n",
    "\n",
    "fig, axs = plt.subplots(num_linhas, num_colunas, figsize=(15, 10))\n",
    "\n",
    "# Iterar sobre as colunas do DataFrame\n",
    "for i, column in enumerate(colunas[:-1]):\n",
    "    # Calcular a média do preço para cada valor único na coluna\n",
    "    med = data.groupby(column)['price'].mean()\n",
    "    top = med.sort_values(ascending=False).head(10)\n",
    "    \n",
    "    # Truncate long labels and append ellipsis\n",
    "    truncated_labels = [str(val)[:10] + '...' if len(str(val)) > 10 else str(val) for val in top.index]\n",
    "\n",
    "    # Determine the subplot index\n",
    "    linha = i // num_colunas\n",
    "    coluna = i % num_colunas\n",
    "\n",
    "    # Plotar o gráfico de barras para a média do preço por valor\n",
    "    axs[linha, coluna].bar(truncated_labels, top.values, color='deepskyblue')\n",
    "    axs[linha, coluna].set_title(f'Média de Preço por {column.upper()}')\n",
    "    axs[linha, coluna].set_ylabel('Média de Preço')\n",
    "    axs[linha, coluna].tick_params(axis='x', rotation=45)  # Rotacionar rótulos do eixo x\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### análise dos modelos com preço mais altos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=data.sort_values(by='price', ascending=False).head(10)\n",
    "d[['brand', 'model', 'price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.groupby('milage')['price'].mean()\n",
    "d=d.sort_index()\n",
    "plt.scatter(d.index, d.values, marker='o', linestyle='-')\n",
    "plt.title('Preço Médio em Função do Número de Quilômetros')\n",
    "plt.xlabel('Quilometragem')\n",
    "plt.ylabel('Preço Médio')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()  # Ajuste automático da disposição para evitar sobreposição\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### o preço diminui a medida que o nº de quilometros aumenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = data.groupby(['brand', 'model_year'])['price'].describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ENGINE] novos atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Potencia'] = data['engine'].str.extract(r'(\\d+\\.\\d+)HP?')\n",
    "data['Capacidade_Motor'] = data['engine'].str.extract(r'(\\d+\\.\\d+|\\d+)\\s*(?:L|Liter)')\n",
    "data['Numero_Cilindros'] = data['engine'].str.extract(r'(?:V(\\d+)|I-(\\d+)|I(\\d+)|(\\d+) Cylinder)').apply(lambda x: next(filter(lambda y: pd.notna(y), x), None), axis=1)\n",
    "# data['Tipo_Combustivel'] = data['engine'].str.extract(r'(Gasoline Fuel|Flexible Fuel|Electric)')\n",
    "data['Numero_Valvulas'] = data['engine'].str.extract(r'( \\d+)V')\n",
    "\n",
    "data['Potencia'] = pd.to_numeric(data['Potencia'], errors='coerce')\n",
    "data['Capacidade_Motor'] = pd.to_numeric(data['Capacidade_Motor'], errors='coerce')\n",
    "data['Numero_Cilindros'] = pd.to_numeric(data['Numero_Cilindros'], errors='coerce')\n",
    "data['Numero_Valvulas'] = pd.to_numeric(data['Numero_Valvulas'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[['engine', 'Potencia', 'Capacidade_Motor',  'Numero_Cilindros',  'Numero_Valvulas' ]].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=len(data[data['Numero_Valvulas'].isnull()])\n",
    "d\n",
    "# d[['engine', 'Potencia', 'Capacidade_Motor',  'Numero_Cilindros',  'Numero_Valvulas' ]].head(50)\n",
    "# data[['engine', 'Potencia', 'Capacidade_Motor',  'Numero_Cilindros',  'Numero_Valvulas' ]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BARPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame with columns of attributes and 'price'\n",
    "# Let's calculate the mean price for each attribute (except the last column)\n",
    "\n",
    "# List to store the generated plots\n",
    "columns = ['Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas']\n",
    "\n",
    "num_linhas = 2\n",
    "num_colunas = 2\n",
    "\n",
    "fig, axs = plt.subplots(num_linhas, num_colunas, figsize=(10, 5))\n",
    "\n",
    "# Iterar sobre as colunas do DataFrame\n",
    "for i, column in enumerate(columns):\n",
    "    # Calcular a média do preço para cada valor único na coluna\n",
    "    med = data.groupby(column)['price'].mean()\n",
    "    top = med.sort_values(ascending=False).head(13)\n",
    "    \n",
    "    # Truncate long labels and append ellipsis\n",
    "    truncated_labels = [str(val)[:10] + '...' if len(str(val)) > 10 else str(val) for val in top.index]\n",
    "\n",
    "    # Determine the subplot index\n",
    "    linha = i // num_colunas\n",
    "    coluna = i % num_colunas\n",
    "\n",
    "    # Plotar o gráfico de barras para a média do preço por valor\n",
    "    axs[linha, coluna].bar(truncated_labels, top.values, color='blueviolet')\n",
    "    axs[linha, coluna].set_title(f'Média de Preço por {column.upper()}')\n",
    "    axs[linha, coluna].set_ylabel('Média de Preço')\n",
    "    axs[linha, coluna].tick_params(axis='x', rotation=45)  # Rotacionar rótulos do eixo x\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[data['Numero_Valvulas'] == 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Numero_Valvulas'].unique())\n",
    "sorted(list(data['Numero_Valvulas'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Numero_Cilindros'].unique())\n",
    "list(sorted(data['Numero_Cilindros'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data['Capacidade_Motor'].unique())\n",
    "#sorted(list(data['Capacidade_Motor'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(data['Potencia'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### verificação de possíveis valores únicos reportados pela análise do boxplot preço / marca no R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['brand'] == 'Maybach'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('train_ccols.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SUBSETS] com dataset W/ ENGINE caract-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)\n",
    "p=pd.read_csv('train_ccols.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituir pela mediana :\n",
    "- num valvulas\n",
    "- num cilindros\n",
    "- potencia\n",
    "- capacidade_motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = p['Numero_Valvulas'].median()\n",
    "m2 = p['Numero_Cilindros'].median()\n",
    "m3 = p['Potencia'].median()\n",
    "m4 = p['Capacidade_Motor'].median()\n",
    "\n",
    "p['Numero_Valvulas'].fillna(m, inplace=True)\n",
    "p['Numero_Cilindros'].fillna(m2, inplace=True)\n",
    "p['Potencia'].fillna(m3, inplace=True)\n",
    "p['Capacidade_Motor'].fillna(m4, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['clean_title'] = p['clean_title'].fillna('No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRANSMISSION SEP -> Novo atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "p['T2'] = p['transmission'].str.extract(r'(\\d+)')\n",
    "p['T2'] = pd.to_numeric(p['T2'], errors='coerce')\n",
    "m5 = p['T2'].mean() \n",
    "p['T2'].fillna(round(m5), inplace=True)\n",
    "#p.head()\n",
    "#p['T2'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nova categoria k(means) -> Categoria_ET   (engine+ transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = p[['Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "n_clusters = 5\n",
    "\n",
    "# Aplicar o algoritmo K-means para agrupar os carros em clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Adicionar uma nova coluna 'Categoria' ao DataFrame com base nos clusters\n",
    "p['Categoria_ET'] = kmeans.labels_\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Contagem de amostras em cada categoria\n",
    "categoria_counts = p['Categoria_ET'].value_counts().sort_index()\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "plt.bar(categoria_counts.index, categoria_counts.values)\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "plt.xlabel('Categoria_ET')\n",
    "plt.ylabel('Número de amostras')\n",
    "plt.title('Distribuição das Categorias')\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['Categoria_ET'] = p['Categoria_ET'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria Marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = p['brand'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência Marca'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência Marca'\n",
    "    else:\n",
    "        return 'Média Frequência Marca'\n",
    "    \n",
    "\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "p['Categoria_Marca'] = p['brand'].map(frequencias.apply(categorizar))\n",
    "\n",
    "p['Categoria_Marca'] = p['Categoria_Marca'].astype('category')\n",
    "p['Categoria_Marca'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = p['model'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência Modelo'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência Modelo'\n",
    "    else:\n",
    "        return 'Média Frequência Modelo'\n",
    "\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "p['Categoria_Modelo'] = p['model'].map(frequencias.apply(categorizar))\n",
    "p['Categoria_Modelo'] = p['Categoria_Modelo'].astype('category')\n",
    "p['Categoria_Modelo'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Substituição de valores nulos e '-' PELA MODA\n",
    "- Remoção outliers LOF\n",
    "- Variavies cat -> numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL's substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fuel_type + engine + ext_col + int_col + accident + transmission (subsituir na's pela moda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['fuel_type'].unique()\n",
    "data1['fuel_type'].isnull().sum()\n",
    "data1['fuel_type'].fillna('Eletric', inplace=True)\n",
    "mod = data1['fuel_type'].mode()[0]\n",
    "\n",
    "data1['fuel_type'] = data1['fuel_type'].replace('–', mod)\n",
    "data1['fuel_type'].unique()\n",
    "\n",
    "mod1=data1['accident'].mode()[0]\n",
    "data1['accident'].fillna(mod1, inplace=True)\n",
    "\n",
    "mod3=data1['engine'].mode()[0]\n",
    "data1['engine'] = data1['engine'].replace('–', mod3)\n",
    "\n",
    "mod5=data1['ext_col'].mode()[0]\n",
    "data1['ext_col'] = data1['ext_col'].replace('–', mod5)\n",
    "\n",
    "mod6=data1['int_col'].mode()[0]\n",
    "data1['int_col'] = data1['int_col'].replace('–', mod6)\n",
    "\n",
    "mod7=data1['transmission'].mode()[0]\n",
    "data1['transmission'] = data1['transmission'].replace('–', mod6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria cor interna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data1['int_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência ext_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência ext_col'\n",
    "    elif limite_baixa < frequencia < limite_alta:  # Verifica se a frequência está entre os limites\n",
    "        return 'Média Frequência ext_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data1['Categoria_IntCol'] = data1['int_col'].map(frequencias.apply(categorizar))\n",
    "data1['Categoria_IntCol'] = data1['Categoria_IntCol'].astype('category')\n",
    "data1['Categoria_IntCol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categoria cor externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data1['ext_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência ext_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência ext_col'\n",
    "    elif limite_baixa < frequencia < limite_alta:  # Verifica se a frequência está entre os limites\n",
    "        return 'Média Frequência ext_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data1['Categoria_ExtCol'] = data1['ext_col'].map(frequencias.apply(categorizar))\n",
    "data1['Categoria_ExtCol'] = data1['Categoria_ExtCol'].astype('category')\n",
    "data1['Categoria_ExtCol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Selecionar apenas as variáveis numéricas\n",
    "numeric_df = data1.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calcular a correlação de Spearman\n",
    "spearman_corr = numeric_df.corr(method='spearman')\n",
    "\n",
    "# Visualizar a matriz de correlação de Spearman\n",
    "print(\"Matriz de correlação de Spearman:\")\n",
    "print(spearman_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#va categorica\n",
    "categorical_columns = data1.select_dtypes(include=['object','category']).columns\n",
    "correlations = {}\n",
    "for column in categorical_columns:\n",
    "    corr, _ = spearmanr(data1[column], data1['price'])\n",
    "    correlations[column] = corr\n",
    "\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier por IQR -> V.a Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices_dict = {}\n",
    "\n",
    "# Variáveis Numéricas\n",
    "for column in data1.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    Q1 = data1[column].quantile(0.25)\n",
    "    Q3 = data1[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    outlier_conditional = ((data1[column] > Q1 - 1.5*IQR) & (data1[column] < Q3 + 1.5*IQR))\n",
    "\n",
    "    outlier_indices_dict[column] = data1.loc[~outlier_conditional].index\n",
    "    \n",
    "    num_outliers = len(data1[~outlier_conditional])\n",
    "    print(f\"Número de outliers em '{column}': {num_outliers}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### O número de válvulas têm muito pouca correlação com o preço -> N utiliza-se essa coluna para os cenários!\n",
    "###### Remove-se os 6 registros da capacidade do motor e os 57 com num de cilindros e 376 do T2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover registros com outliers (cujo correlação baixo com preço)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices_dict['Capacidade_Motor']\n",
    "outlier_indices_dict['Numero_Cilindros']\n",
    "outlier_indices_dict['T2']\n",
    "\n",
    "data1_s_out = data1.copy()\n",
    "\n",
    "outlier_indices_to_drop = outlier_indices_dict['Capacidade_Motor'].union(outlier_indices_dict['Numero_Cilindros']).union(outlier_indices_dict['T2'])\n",
    "data1_s_out.drop(outlier_indices_to_drop, inplace=True)\n",
    "\n",
    "# Verifica o tamanho do novo conjunto de dados\n",
    "print(\"Número de registros no novo conjunto de dados sem outliers:\", len(data1_s_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('subset_1.csv', index=False) # sem normalizar\n",
    "data1_s_out.to_csv('subset_1_s_out.csv', index=False) # sem normalizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  substituir '-' por desconhecido\n",
    "- Remoção outliers LOF\n",
    "- Variavies cat -> numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL's substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fuel_type'].unique()\n",
    "data2['fuel_type'].isnull().sum()\n",
    "data2['fuel_type'].fillna('Eletric', inplace=True)\n",
    "data2['fuel_type'] = data2['fuel_type'].replace('–', 'desconhecido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accident + engine + transmission + ex_col + int_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['accident'].fillna('desconhecido', inplace=True)\n",
    "data2['engine'] = data2['engine'].replace('–', 'desconhecido')\n",
    "data2['transmission'] = data2['transmission'].replace('–', 'desconhecido')\n",
    "data2['ext_col'] = data2['ext_col'].replace('–', 'desconhecido')\n",
    "data2['int_col'] = data2['int_col'].replace('–', 'desconhecido')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria cor interna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data2['int_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência int_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência int_col'\n",
    "    else:\n",
    "        return 'Média Frequência int_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data2['Categoria_IntCol'] = data2['int_col'].map(frequencias.apply(categorizar))\n",
    "data2['Categoria_IntCol'] = data2['Categoria_IntCol'].astype('category')\n",
    "data2['Categoria_IntCol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria cor externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data2['ext_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência ext_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência ext_col'\n",
    "    else:\n",
    "        return 'Média Frequência ext_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data2['Categoria_ExtCol'] = data2['ext_col'].map(frequencias.apply(categorizar))\n",
    "data2['Categoria_ExtCol'] = data2['Categoria_ExtCol'].astype('category')\n",
    "data2['Categoria_ExtCol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Selecionar apenas as variáveis numéricas\n",
    "numeric_df = data2.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calcular a correlação de Spearman\n",
    "spearman_corr = numeric_df.corr(method='spearman')\n",
    "\n",
    "# Visualizar a matriz de correlação de Spearman\n",
    "print(\"Matriz de correlação de Spearman:\")\n",
    "print(spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#va categorica\n",
    "categorical_columns = data2.select_dtypes(include=['object','category']).columns\n",
    "correlations = {}\n",
    "for column in categorical_columns:\n",
    "    corr, _ = spearmanr(data2[column], data2['price'])\n",
    "    correlations[column] = corr\n",
    "\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier por IQR -> V.a Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis Numéricas\n",
    "for column in data2.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    Q1 = data2[column].quantile(0.25)\n",
    "    Q3 = data2[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    outlier_conditional = ((data2[column] > Q1 - 1.5*IQR) & (data2[column] < Q3 + 1.5*IQR))\n",
    "    outlier_indices_dict[column] = data2.loc[~outlier_conditional].index\n",
    "    \n",
    "    num_outliers = len(data2[~outlier_conditional])\n",
    "    print(f\"Número de outliers em '{column}': {num_outliers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover registros com outliers (cujo correlação baixo preço)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices_dict['Capacidade_Motor']\n",
    "outlier_indices_dict['Numero_Cilindros']\n",
    "outlier_indices_dict['T2']\n",
    "\n",
    "data2_s_out = data2.copy()\n",
    "\n",
    "outlier_indices_to_drop = outlier_indices_dict['Capacidade_Motor'].union(outlier_indices_dict['Numero_Cilindros']).union(outlier_indices_dict['T2'])\n",
    "data2_s_out.drop(outlier_indices_to_drop, inplace=True)\n",
    "\n",
    "# Verifica o tamanho do novo conjunto de dados\n",
    "print(\"Número de registros no novo conjunto de dados sem outliers:\", len(data2_s_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('subset_2.csv', index=False) # sem normalizar\n",
    "data2_s_out.to_csv('subset_2_s_out.csv', index=False) # sem normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como subset 1 é muito parecido com subset 2, só vamos utilizar o subset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cenário 1 -> todas as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subset_1=pd.read_csv('subset_1.csv')\n",
    "subset_1_s_out=pd.read_csv('subset_1_s_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajuste para usar a categoria \"brand\". Temos uma marca 'Maybatch' que só existe 1x no dataset. Duplicar esse registro para poder aparecer no treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maybach_rows = subset_1[subset_1['brand'] == 'Maybach']\n",
    "duplicated_rows = maybach_rows.copy()\n",
    "\n",
    "# Adicionar as linhas duplicadas ao DataFrame original\n",
    "subset_1 = pd.concat([subset_1, duplicated_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = subset_1.drop(['price'], axis=1) \n",
    "y1 = subset_1['price'] \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizados e label logaritmizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Highlander Platinum', 'Hardtop Cooper', 'AMG GLE 63 S Coupe 4MATIC', 'Transit-250 Base', 'RS 7 4.0T quattro', '640 i', 'X3 M AWD', 'Xterra Pro-4X', 'Traverse High Country', 'GLA-Class GLA 45 AMG', 'LaCrosse Leather', 'Wrangler Unlimited Sport S', 'Charger Base', 'Maverick XLT', '86 860 Special Edition', 'Mazda3 s Sport', 'A5 Sportback S line Premium Plus', '440 i xDrive', 'Corsair Reserve', 'RS 7 4.0T', 'Ram 1500 Quad Cab', 'FX37 Base', 'Crosstour EX-L', 'Rover Range Rover Supercharged', 'Q70h Base', 'RX-8 R3', 'Beetle 1.8T', 'Rover LR2 HSE', 'XLR Base', 'Pacifica Launch Edition', 'C-Class C300 4MATIC', 'ATS 3.6L Luxury', 'STS V6', 'Model S 70D', '9-3 Aero', 'Wrangler S', 'Dart SE', 'C-Class 4MATIC Sedan', 'Pathfinder SV', 'Viper GTC', 'Rover LR4 HSE LUX Landmark Edition', 'Odyssey EX-L', 'CX-5 Touring', 'Highlander Limited Platinum', 'Quattroporte S GranLusso', 'Escalade ESV Platinum Edition', 'Ram 1500 Laramie Mega Cab', 'AMG S 63 Base 4MATIC', 'Focus SEL', 'Sprinter 4500 High Roof', '718 Cayman GTS', 'Palisade Limited', 'Camry XSE', 'Durango SLT', 'CC 2.0T Sport', 'Z4 3.0si', '320 i xDrive', 'Boxster Black Edition', 'Silverado 3500 LTZ', 'Mustang SVT Cobra', 'Maverick XL', 'SSR Base', 'Grand Cherokee L Summit', 'Malibu LT', 'RX-8 Sport', 'M8 Competition', 'Blazer 1LT', 'V60 Cross Country T5', 'Sierra 1500 SLE', 'Suburban LTZ', 'Huracan EVO Coupe', 'Cayenne GTS Coupe AWD', 'Transit Connect XL w/Rear Symmetrical Doors', 'Gladiator Freedom', 'Escape Limited', 'Edge SE', 'Genesis Coupe 3.8 Grand Touring', 'LX 600 Premium', 'Beetle 2.0T S', 'G80 3.3T Sport', 'Baja Base', 'A6 3.0 TDI Premium Plus', '328 xi', 'GLE 350 GLE 350', '4Runner Limited Nightshade', 'Rover Range Rover Evoque R-Dynamic HSE', 'XF Luxury', 'Beetle 2.0T Final Edition SE', 'A7 3.0T Premium Plus', '370Z NISMO Tech', 'Civic Si Base', 'A7 55 Premium Plus', 'Terrain SLE', 'Model S 90D', 'X3 M40i', 'Fusion Hybrid Titanium', 'M3 Competition xDrive', 'R8 5.2 V10 performance', 'tC Base', 'GLC 300 Base', 'Caprice Classic Base', 'Charger R/T 392', 'Sorento Hybrid EX', 'RS Q8 4.0T quattro', 'Town Car Base', 'Forester 2.5 X', 'LaCrosse Base', 'GV70 2.5T', 'Caliber Express', 'XF S', 'XT6 Premium Luxury AWD', 'Sprinter 3500 High Roof', 'RS Q8 4.0T', 'S60 Recharge Plug-In Hybrid T8 Inscription', 'LYRIQ Luxury', 'S4 3.0 Prestige', 'Romeo Stelvio Quadrifoglio', 'tC Anniversary Edition', 'RX 350 RX 350 F SPORT Handling', '4Runner Venture', '240SX Base', 'M8 Gran Coupe Competition', '4Runner Sport', '750 750i xDrive', 'A3 2.0T', 'F-TYPE V6 S', 'Air Pure', 'TLX', 'GS 350 F Sport', 'Colorado Z85', 'Silverado 2500 WT', 'Genesis 5', 'Rover Discovery Sport SE', 'Grand Wagoneer Series III', 'Savana 2500 Work Van', 'GLE 350 Base', 'Lucerne CXL', 'Express 1500 Work Van', 'Trailblazer LT', 'A6 55 Prestige', '428 i xDrive SULEV', 'V60 T6 R-Design Platinum', 'Rogue Sport S', 'A8 L 3.0T', 'Versa 1.6 SL', 'Tundra SR5 Access Cab', 'Mazda3 Grand Touring', 'F-PACE 30t R-Sport', 'X5 xDrive40e', 'Sprinter 3500XD High Roof', 'Cayenne E-Hybrid S Platinum Edition', 'Cruze LT Automatic', 'S-Class S 65 AMG', 'Protege DX', 'S-10 LS', 'Sierra 1500 AT4', 'MKZ Select', 'Silverado 1500 LTZ', 'Dakota SLT', 'Veloster Turbo R-Spec', 'F-150 FX4', 'Camry SE', 'Enclave 1XL', 'Forte LXS', 'MKC Base', 'Golf GTI 2.0T Autobahn', 'S5 3.0T Premium Plus', 'AMG GLE AMG GLE 63 S-Model 4MATIC', 'Charger SE', 'BRZ Premium', 'Rover Range Rover 5.0L Supercharged Autobiography', 'Lancer Evolution IX', 'S60 T6 Momentum', 'Suburban RST', 'F-TYPE S British Design Edition', 'QX80 Luxe', '750 Li', 'Huracan Tecnica Coupe', 'Frontier SE Crew Cab', 'Golf Auto TSI S', 'Panamera S', 'Ranger Sport SuperCab', 'Gallardo LP570-4 Superleggera', 'Q3 45 S line Premium', 'Q4 e-tron 50 Premium Plus', 'S5 3.0 Premium Plus', 'Niro EV EX', 'Outback 3.0 R VDC Limited', '124 Spider Abarth', 'Yaris L', 'Outback Limited', 'Accord Hybrid Base', 'X5 3.0i', 'Compass High Altitude', 'Navigator L', 'TLX Type S PMC Edition', 'WRX STI Base', 'XT5 Premium Luxury', 'Impreza WRX Premium', 'ID.4 Pro S', 'Impreza WRX Base', 'GLA-Class GLA 250 4MATIC', 'Prius Two', 'Marauder Base', 'E-Class D 2.5 Turbo', 'Titan XD S', 'Mustang Mach-E GT', 'Martin DB7 Vantage Volante', 'A8 4.0T', 'GL-Class GL 450 4MATIC', 'XT6 Sport AWD', 'RDX w/A-Spec Package', 'Ascent Limited 7-Passenger', 'Tiguan 2.0T SE', 'Huracan LP580-2S', 'A6 3.0T Premium Plus', 'Corolla Hybrid LE', 'R8 5.2', 'IONIQ Plug-In Hybrid SEL', 'QX60 AUTOGRAPH', 'Sienna XLE Limited', 'Accent SEL', 'Passport Elite', 'Sentra SR', 'Ram 2500 SLT Quad Cab', 'S-Class S 450', 'Bentayga S', 'Golf GTI 2.0T SE w/Performance Package 4-Door', 'TT 3.2 Cabriolet quattro', 'Mazda6 i Grand Touring', 'Rover Range Rover Velar SVAutobiography Dynamic Edition'] in column 1 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m make_column_transformer(\n\u001b[0;32m      9\u001b[0m     (StandardScaler(), features_num),\n\u001b[0;32m     10\u001b[0m     (OneHotEncoder(), features_cat),\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m X1_train_norm \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(X1_train)\n\u001b[1;32m---> 14\u001b[0m X1_test_norm \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# y1_train_log = np.log(y1_train)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# y1_test_log = np.log(y1_test)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1014\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1014\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:823\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    811\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    812\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    813\u001b[0m             delayed(func)(\n\u001b[0;32m    814\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m             )\n\u001b[0;32m    821\u001b[0m         )\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:1283\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params):\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m \n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1023\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m }\n\u001b[1;32m-> 1023\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1030\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Utilizador\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:213\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    209\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    212\u001b[0m     )\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Highlander Platinum', 'Hardtop Cooper', 'AMG GLE 63 S Coupe 4MATIC', 'Transit-250 Base', 'RS 7 4.0T quattro', '640 i', 'X3 M AWD', 'Xterra Pro-4X', 'Traverse High Country', 'GLA-Class GLA 45 AMG', 'LaCrosse Leather', 'Wrangler Unlimited Sport S', 'Charger Base', 'Maverick XLT', '86 860 Special Edition', 'Mazda3 s Sport', 'A5 Sportback S line Premium Plus', '440 i xDrive', 'Corsair Reserve', 'RS 7 4.0T', 'Ram 1500 Quad Cab', 'FX37 Base', 'Crosstour EX-L', 'Rover Range Rover Supercharged', 'Q70h Base', 'RX-8 R3', 'Beetle 1.8T', 'Rover LR2 HSE', 'XLR Base', 'Pacifica Launch Edition', 'C-Class C300 4MATIC', 'ATS 3.6L Luxury', 'STS V6', 'Model S 70D', '9-3 Aero', 'Wrangler S', 'Dart SE', 'C-Class 4MATIC Sedan', 'Pathfinder SV', 'Viper GTC', 'Rover LR4 HSE LUX Landmark Edition', 'Odyssey EX-L', 'CX-5 Touring', 'Highlander Limited Platinum', 'Quattroporte S GranLusso', 'Escalade ESV Platinum Edition', 'Ram 1500 Laramie Mega Cab', 'AMG S 63 Base 4MATIC', 'Focus SEL', 'Sprinter 4500 High Roof', '718 Cayman GTS', 'Palisade Limited', 'Camry XSE', 'Durango SLT', 'CC 2.0T Sport', 'Z4 3.0si', '320 i xDrive', 'Boxster Black Edition', 'Silverado 3500 LTZ', 'Mustang SVT Cobra', 'Maverick XL', 'SSR Base', 'Grand Cherokee L Summit', 'Malibu LT', 'RX-8 Sport', 'M8 Competition', 'Blazer 1LT', 'V60 Cross Country T5', 'Sierra 1500 SLE', 'Suburban LTZ', 'Huracan EVO Coupe', 'Cayenne GTS Coupe AWD', 'Transit Connect XL w/Rear Symmetrical Doors', 'Gladiator Freedom', 'Escape Limited', 'Edge SE', 'Genesis Coupe 3.8 Grand Touring', 'LX 600 Premium', 'Beetle 2.0T S', 'G80 3.3T Sport', 'Baja Base', 'A6 3.0 TDI Premium Plus', '328 xi', 'GLE 350 GLE 350', '4Runner Limited Nightshade', 'Rover Range Rover Evoque R-Dynamic HSE', 'XF Luxury', 'Beetle 2.0T Final Edition SE', 'A7 3.0T Premium Plus', '370Z NISMO Tech', 'Civic Si Base', 'A7 55 Premium Plus', 'Terrain SLE', 'Model S 90D', 'X3 M40i', 'Fusion Hybrid Titanium', 'M3 Competition xDrive', 'R8 5.2 V10 performance', 'tC Base', 'GLC 300 Base', 'Caprice Classic Base', 'Charger R/T 392', 'Sorento Hybrid EX', 'RS Q8 4.0T quattro', 'Town Car Base', 'Forester 2.5 X', 'LaCrosse Base', 'GV70 2.5T', 'Caliber Express', 'XF S', 'XT6 Premium Luxury AWD', 'Sprinter 3500 High Roof', 'RS Q8 4.0T', 'S60 Recharge Plug-In Hybrid T8 Inscription', 'LYRIQ Luxury', 'S4 3.0 Prestige', 'Romeo Stelvio Quadrifoglio', 'tC Anniversary Edition', 'RX 350 RX 350 F SPORT Handling', '4Runner Venture', '240SX Base', 'M8 Gran Coupe Competition', '4Runner Sport', '750 750i xDrive', 'A3 2.0T', 'F-TYPE V6 S', 'Air Pure', 'TLX', 'GS 350 F Sport', 'Colorado Z85', 'Silverado 2500 WT', 'Genesis 5', 'Rover Discovery Sport SE', 'Grand Wagoneer Series III', 'Savana 2500 Work Van', 'GLE 350 Base', 'Lucerne CXL', 'Express 1500 Work Van', 'Trailblazer LT', 'A6 55 Prestige', '428 i xDrive SULEV', 'V60 T6 R-Design Platinum', 'Rogue Sport S', 'A8 L 3.0T', 'Versa 1.6 SL', 'Tundra SR5 Access Cab', 'Mazda3 Grand Touring', 'F-PACE 30t R-Sport', 'X5 xDrive40e', 'Sprinter 3500XD High Roof', 'Cayenne E-Hybrid S Platinum Edition', 'Cruze LT Automatic', 'S-Class S 65 AMG', 'Protege DX', 'S-10 LS', 'Sierra 1500 AT4', 'MKZ Select', 'Silverado 1500 LTZ', 'Dakota SLT', 'Veloster Turbo R-Spec', 'F-150 FX4', 'Camry SE', 'Enclave 1XL', 'Forte LXS', 'MKC Base', 'Golf GTI 2.0T Autobahn', 'S5 3.0T Premium Plus', 'AMG GLE AMG GLE 63 S-Model 4MATIC', 'Charger SE', 'BRZ Premium', 'Rover Range Rover 5.0L Supercharged Autobiography', 'Lancer Evolution IX', 'S60 T6 Momentum', 'Suburban RST', 'F-TYPE S British Design Edition', 'QX80 Luxe', '750 Li', 'Huracan Tecnica Coupe', 'Frontier SE Crew Cab', 'Golf Auto TSI S', 'Panamera S', 'Ranger Sport SuperCab', 'Gallardo LP570-4 Superleggera', 'Q3 45 S line Premium', 'Q4 e-tron 50 Premium Plus', 'S5 3.0 Premium Plus', 'Niro EV EX', 'Outback 3.0 R VDC Limited', '124 Spider Abarth', 'Yaris L', 'Outback Limited', 'Accord Hybrid Base', 'X5 3.0i', 'Compass High Altitude', 'Navigator L', 'TLX Type S PMC Edition', 'WRX STI Base', 'XT5 Premium Luxury', 'Impreza WRX Premium', 'ID.4 Pro S', 'Impreza WRX Base', 'GLA-Class GLA 250 4MATIC', 'Prius Two', 'Marauder Base', 'E-Class D 2.5 Turbo', 'Titan XD S', 'Mustang Mach-E GT', 'Martin DB7 Vantage Volante', 'A8 4.0T', 'GL-Class GL 450 4MATIC', 'XT6 Sport AWD', 'RDX w/A-Spec Package', 'Ascent Limited 7-Passenger', 'Tiguan 2.0T SE', 'Huracan LP580-2S', 'A6 3.0T Premium Plus', 'Corolla Hybrid LE', 'R8 5.2', 'IONIQ Plug-In Hybrid SEL', 'QX60 AUTOGRAPH', 'Sienna XLE Limited', 'Accent SEL', 'Passport Elite', 'Sentra SR', 'Ram 2500 SLT Quad Cab', 'S-Class S 450', 'Bentayga S', 'Golf GTI 2.0T SE w/Performance Package 4-Door', 'TT 3.2 Cabriolet quattro', 'Mazda6 i Grand Touring', 'Rover Range Rover Velar SVAutobiography Dynamic Edition'] in column 1 during transform"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "features_num=X1.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "features_cat=X1.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), features_num),\n",
    "    (OneHotEncoder(), features_cat),\n",
    ")\n",
    "\n",
    "X1_train_norm = preprocessor.fit_transform(X1_train)\n",
    "X1_test_norm = preprocessor.transform(X1_test)\n",
    "# y1_train_log = np.log(y1_train)\n",
    "# y1_test_log = np.log(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[X1['brand']=='Maybach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sem outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1out = subset_1_s_out.csv.drop(['price'], axis=1) \n",
    "y1out = subset_1_s_out.csv['price'] \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1out_train, X1out_test, y1out_train, y1out_test = train_test_split(X1out, y1out, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizados e label logaritmizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "features_num=data2.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "features_cat=data2.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), features_num),\n",
    "    (OneHotEncoder(), features_cat),\n",
    ")\n",
    "\n",
    "X1out_train_norm = preprocessor.fit_transform(X1_train)\n",
    "X1out_valid_norm = preprocessor.transform(X1_test)\n",
    "y1out_train_log = np.log(y1_train)\n",
    "y1out_test_log = np.log(y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cenário 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck1=ck.loc[:, ['model_year', 'price', 'Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(características do carro (só com variáveis numéricas)) do subset 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar Data / Treinar e Avaliar Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "# from sklearn import datasets\n",
    "# from slickml.metrics import (\n",
    "#     RegressionMetrics,\n",
    "# )  # downloaded from https://github.com/slickml/slick-ml # btw pip install slickml\n",
    "from matplotlib import pyplot as plt\n",
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = ck1.drop(['price'], axis=1) \n",
    "y = ck1['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True) # para var. categóricas\n",
    "# Option 1: Fill missing values, for example with the median or mean\n",
    "# X.fillna(X.median(), inplace=True)\n",
    "\n",
    "# Option 2: Drop rows with missing values\n",
    "# X.dropna(inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting actual vs predicted prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "plt.title('Actual vs Predicted Car Prices (Multiple Linear Regression)')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and predict with Random Forest Regressor\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train, y_train)\n",
    "pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics for Random Forest\n",
    "from slickml.metrics import RegressionMetrics\n",
    "\n",
    "reg_metrics = RegressionMetrics(y_test, pred)\n",
    "reg_metrics.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "dados_numericos = data.select_dtypes(include=['number'])\n",
    "correlation_matrix = dados_numericos.corr(method='spearman')\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# preço está bastante correlacionado com potência e ano de fábrico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlação p/ preço/nº valvulas diminui muito quando se substitui NaN (0.51 para 0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionar as colunas necessárias a partir do df SEM OUTLIERS\n",
    "ck3=ck.loc[:, ['model_year', 'price', 'Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2', 'fuel_type', 'accident', 'clean_title']]\n",
    "X = ck3.drop(['price'], axis=1) \n",
    "y = ck3['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True) # para var. categóricas \n",
    "# Option 1: Fill missing values, for example with the median or mean\n",
    "X.fillna(X.median(), inplace=True)\n",
    "\n",
    "# Option 2: Drop rows with missing values\n",
    "# X.dropna(inplace=True)´\n",
    "\n",
    "# nao precisa mais desse codigo em cima dessa linha\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting actual vs predicted prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "plt.title('Actual vs Predicted Car Prices (Multiple Linear Regression)')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "erro um pouco menor do que R1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_color(color):\n",
    "    return color.split()[0]\n",
    "\n",
    "# Aplicar a função à coluna 'Cor'\n",
    "p['simp_int_col'] = p['int_col'].apply(simplify_color)\n",
    "p['simp_ext_col'] = p['ext_col'].apply(simplify_color) # de 265 p/ 191\n",
    "# n vale a pena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD -> Subset 2  -cenário 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset2 = pd.read_csv('subset_2.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir o dataset em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn import datasets\n",
    "# from slickml.metrics import (\n",
    "#     RegressionMetrics,\n",
    "# )   # downloaded from https://github.com/slickml/slick-ml\n",
    "from matplotlib import pyplot as plt\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subset2.drop(['price'], axis=1)  # sem os outliers \n",
    "y = subset2['price'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divida os dados transformados em conjuntos de treinamento e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_tr[['price', 'model_year', 'Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2','milage']] = scaler.fit_transform(X_tr[['price', 'model_year', 'Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2', 'milage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "DT.fit(X_tr, y_tr)\n",
    "pred3 = DT.predict(X_ts)\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# dt1_model = DecisionTreeRegressor(random_state=0,\n",
    "#                                            criterion='mse')\n",
    "# dt1_model.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(DT, filled=True, feature_names=X_tr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics for Decision Tree\n",
    "reg_metrics3 = RegressionMetrics(y_ts, pred3)\n",
    "reg_metrics3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
    "\n",
    "# Calcular as predições\n",
    "preds = DT.predict(X_ts)\n",
    "\n",
    "# Calcular métricas de regressão\n",
    "mse = mean_squared_error(y_ts, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_ts, preds)\n",
    "mae = mean_absolute_error(y_ts, preds)\n",
    "medae = median_absolute_error(y_ts, preds)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Erro Quadrático Médio (MSE):\", mse)\n",
    "print(\"Raiz do Erro Quadrático Médio (RMSE):\", rmse)\n",
    "print(\"Coeficiente de Determinação (R²):\", r2)\n",
    "print(\"Erro Absoluto Médio (MAE):\", mae)\n",
    "print(\"Mediana do Erro Absoluto (MedAE):\", medae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "tree_graph = tree.export_graphviz(DT, out_file=None)\n",
    "graphviz.Source(tree_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AD -> Subset 1- Cenário1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = pd.read_csv('subset_1.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "subset1[['price', 'model_year', 'Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2','milage']] = scaler.fit_transform(subset1[['price', 'model_year', 'Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2', 'milage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "X = subset1.drop(['price'], axis=1)  # sem os outliers \n",
    "y =subset1['price'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divida os dados transformados em conjuntos de treinamento e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "DT.fit(X_tr, y_tr)\n",
    "pred3 = DT.predict(X_ts)\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(DT, filled=True, feature_names=X_tr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
    "\n",
    "# Calcular as predições\n",
    "preds = DT.predict(X_ts)\n",
    "\n",
    "# Calcular métricas de regressão\n",
    "mse = mean_squared_error(y_ts, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_ts, preds)\n",
    "mae = mean_absolute_error(y_ts, preds)\n",
    "medae = median_absolute_error(y_ts, preds)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Erro Quadrático Médio (MSE):\", mse)\n",
    "print(\"Raiz do Erro Quadrático Médio (RMSE):\", rmse)\n",
    "print(\"Coeficiente de Determinação (R²):\", r2)\n",
    "print(\"Erro Absoluto Médio (MAE):\", mae)\n",
    "print(\"Mediana do Erro Absoluto (MedAE):\", medae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
