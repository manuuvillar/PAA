{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)\n",
    "data=pd.read_csv('train.csv') # dataset do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dtypes\n",
    "data.info() #milage\n",
    "# data.head()\n",
    "# data.tail()\n",
    "# data.shape #(3207, 12)\n",
    "# data.nunique() # valores unicos para cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo mais antigo e mais novo:\n",
    "antigo=data['model_year'].min()\n",
    "novo=data['model_year'].max()\n",
    "print(antigo,novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correção: 'milage' -> INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#milage:\n",
    "valores_corrigidos=[]\n",
    "for milage in data['milage']: # para cada quilometragem do dataset\n",
    "    separa=re.split(r'[ ]',milage) # sepagar o numero do mi\n",
    "    numero=separa[0] # numero\n",
    "    letra=separa[1] # mi\n",
    "    verifica=re.search(r'^[0-9]+[,]?[0-9]+$',numero) # verifica se o numeros sao sempre iguais(com casas decimais ou não)\n",
    "    verifica2=re.search(r'^mi\\.$',letra) # verifica se a letra é sempre mi\n",
    "    if verifica and verifica2: # se seguir o padra numero + mi:\n",
    "        numero=int(re.sub(r',','',numero)) # retira a , dos numeros e passa para inteiro ( estavam em obj)\n",
    "        valores_corrigidos.append(numero)\n",
    "    else: \n",
    "        print(milage,False) # tem dados diferentes no dataset\n",
    "\n",
    "data['milage']=valores_corrigidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificaçao\n",
    "for m in data['milage']:\n",
    "    if not isinstance(m, (int)):\n",
    "        print('dado incorreto')\n",
    "# tudo certo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NULL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fuel_type'].value_counts() # –  38 ( existem 38 linhas com (-) -> nao se sabe)\n",
    "data['accident'].value_counts()\n",
    "data['clean_title'].value_counts() # Yes -> 2740, os restantes são valores nulos (nan)\n",
    "# data['clean_title'].unique()\n",
    "# verificar outros tipos de dizer valores nulos: ( como (-) por exemplo)\n",
    "data['brand'].value_counts() # tudo certo\n",
    "data['model'].nunique() # tudo certo\n",
    "data['model_year'].value_counts() # tudo certo\n",
    "data['engine'].value_counts() # – 38 -> nao se sabe\n",
    "data['transmission'].value_counts() # 4 -> nao se sabe \n",
    "# data['ext_col'].value_counts()# 11 -> nao se sabe\n",
    "# data['int_col'].value_counts() # 98 -> nao se sabe\n",
    "# for preco in data['price']: # tudo certo\n",
    "#     if not isinstance(preco, int):\n",
    "#         print('erro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['milage'])\n",
    "# len(data['milage'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> nº de velocidades na transmissão existentes no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=list(data['transmission'].unique())\n",
    "alls = [int(numero) for string in d2 for numero in re.findall(r'\\d+', string)]\n",
    "list(set(alls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verificar significado de '-' e NaN para o tipo de combustível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.loc[data['fuel_type'] == '–'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['fuel_type'] == '–') & (data['engine'] != '–')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### OS CARROS PARA OS QUAIS O FUEL_TYPE É '-' NÃO INDICADO, TAMBÉM NÃO SE CONHECE A CONFIGURAÇÃO DO MOTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAR QUE OS CARROS COM NAN NO TIPO DE COMBUSTÍVEL SÃO CARROS ELÉTRICOS\n",
    "elec=data[data['fuel_type'].isnull()]\n",
    "pattern = re.compile(r'\\bElectric\\b', flags=re.IGNORECASE)\n",
    "contains_electric = elec['engine'].str.contains(pattern, na=False)\n",
    "# Selecionar todas as linhas que não contêm 'Electric' na coluna 'engine'\n",
    "elec[~contains_electric]\n",
    "# elec[contains_electric].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### os carros com NaN para 'fuel_type' são carros elétricos\n",
    "Tesla --> elétrico\n",
    "Standard Range Battery --> elétrico\n",
    "111.2Ah / FR 70kW / RR 160kW (697V) --> especificidade de baterias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='box',figsize=(15,6),subplots=True) # grafico do codigo acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['model_year']<1990] # outlier do 1º gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['milage']>350000] # outlier do 2º gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['price']>1500000] # outlier 3º gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BARPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que 'data' seja seu DataFrame com colunas de atributos e 'preco'\n",
    "# Vamos calcular a média do preço para cada atributo (exceto a última coluna)\n",
    "data['fuel_type'].fillna('Elétrico', inplace=True)\n",
    "\n",
    "# Lista para armazenar os gráficos gerados\n",
    "colunas = ['brand', 'model', 'model_year', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
    "num_linhas = 3\n",
    "num_colunas = 3\n",
    "\n",
    "fig, axs = plt.subplots(num_linhas, num_colunas, figsize=(15, 10))\n",
    "\n",
    "# Iterar sobre as colunas do DataFrame\n",
    "for i, column in enumerate(colunas[:-1]):\n",
    "    # Calcular a média do preço para cada valor único na coluna\n",
    "    med = data.groupby(column)['price'].mean()\n",
    "    top = med.sort_values(ascending=False).head(10)\n",
    "    \n",
    "    # Truncate long labels and append ellipsis\n",
    "    truncated_labels = [str(val)[:10] + '...' if len(str(val)) > 10 else str(val) for val in top.index]\n",
    "\n",
    "    # Determine the subplot index\n",
    "    linha = i // num_colunas\n",
    "    coluna = i % num_colunas\n",
    "\n",
    "    # Plotar o gráfico de barras para a média do preço por valor\n",
    "    axs[linha, coluna].bar(truncated_labels, top.values, color='deepskyblue')\n",
    "    axs[linha, coluna].set_title(f'Média de Preço por {column.upper()}')\n",
    "    axs[linha, coluna].set_ylabel('Média de Preço')\n",
    "    axs[linha, coluna].tick_params(axis='x', rotation=45)  # Rotacionar rótulos do eixo x\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### análise dos modelos com preço mais altos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=data.sort_values(by='price', ascending=False).head(10)\n",
    "d[['brand', 'model', 'price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.groupby('milage')['price'].mean()\n",
    "d=d.sort_index()\n",
    "plt.scatter(d.index, d.values, marker='o', linestyle='-')\n",
    "plt.title('Preço Médio em Função do Número de Quilômetros')\n",
    "plt.xlabel('Quilometragem')\n",
    "plt.ylabel('Preço Médio')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()  # Ajuste automático da disposição para evitar sobreposição\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### o preço diminui a medida que o nº de quilometros aumenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = data.groupby(['brand', 'model_year'])['price'].describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ENGINE] novos atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Potencia'] = data['engine'].str.extract(r'(\\d+\\.\\d+)HP?')\n",
    "data['Capacidade_Motor'] = data['engine'].str.extract(r'(\\d+\\.\\d+|\\d+)\\s*(?:L|Liter)')\n",
    "data['Numero_Cilindros'] = data['engine'].str.extract(r'(?:V(\\d+)|I-(\\d+)|I(\\d+)|(\\d+) Cylinder)').apply(lambda x: next(filter(lambda y: pd.notna(y), x), None), axis=1)\n",
    "# data['Tipo_Combustivel'] = data['engine'].str.extract(r'(Gasoline Fuel|Flexible Fuel|Electric)')\n",
    "data['Numero_Valvulas'] = data['engine'].str.extract(r'( \\d+)V')\n",
    "\n",
    "data['Potencia'] = pd.to_numeric(data['Potencia'], errors='coerce')\n",
    "data['Capacidade_Motor'] = pd.to_numeric(data['Capacidade_Motor'], errors='coerce')\n",
    "data['Numero_Cilindros'] = pd.to_numeric(data['Numero_Cilindros'], errors='coerce')\n",
    "data['Numero_Valvulas'] = pd.to_numeric(data['Numero_Valvulas'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['engine', 'Potencia', 'Capacidade_Motor',  'Numero_Cilindros',  'Numero_Valvulas' ]].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=len(data[data['Numero_Valvulas'].isnull()])\n",
    "d\n",
    "# d[['engine', 'Potencia', 'Capacidade_Motor',  'Numero_Cilindros',  'Numero_Valvulas' ]].head(50)\n",
    "# data[['engine', 'Potencia', 'Capacidade_Motor',  'Numero_Cilindros',  'Numero_Valvulas' ]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BARPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame with columns of attributes and 'price'\n",
    "# Let's calculate the mean price for each attribute (except the last column)\n",
    "\n",
    "# List to store the generated plots\n",
    "columns = ['Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas']\n",
    "\n",
    "num_linhas = 2\n",
    "num_colunas = 2\n",
    "\n",
    "fig, axs = plt.subplots(num_linhas, num_colunas, figsize=(10, 5))\n",
    "\n",
    "# Iterar sobre as colunas do DataFrame\n",
    "for i, column in enumerate(columns):\n",
    "    # Calcular a média do preço para cada valor único na coluna\n",
    "    med = data.groupby(column)['price'].mean()\n",
    "    top = med.sort_values(ascending=False).head(13)\n",
    "    \n",
    "    # Truncate long labels and append ellipsis\n",
    "    truncated_labels = [str(val)[:10] + '...' if len(str(val)) > 10 else str(val) for val in top.index]\n",
    "\n",
    "    # Determine the subplot index\n",
    "    linha = i // num_colunas\n",
    "    coluna = i % num_colunas\n",
    "\n",
    "    # Plotar o gráfico de barras para a média do preço por valor\n",
    "    axs[linha, coluna].bar(truncated_labels, top.values, color='blueviolet')\n",
    "    axs[linha, coluna].set_title(f'Média de Preço por {column.upper()}')\n",
    "    axs[linha, coluna].set_ylabel('Média de Preço')\n",
    "    axs[linha, coluna].tick_params(axis='x', rotation=45)  # Rotacionar rótulos do eixo x\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[data['Numero_Valvulas'] == 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Numero_Valvulas'].unique())\n",
    "sorted(list(data['Numero_Valvulas'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Numero_Cilindros'].unique())\n",
    "list(sorted(data['Numero_Cilindros'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data['Capacidade_Motor'].unique())\n",
    "#sorted(list(data['Capacidade_Motor'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(data['Potencia'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verificação de possíveis valores únicos reportados pela análise do boxplot preço / marca no R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['brand'] == 'Maybach'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('train_ccols.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SUBSETS] com dataset W/ ENGINE caract-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)\n",
    "p=pd.read_csv('train_ccols.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituir pela mediana :\n",
    "- num valvulas\n",
    "- num cilindros\n",
    "- potencia\n",
    "- capacidade_motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = p['Numero_Valvulas'].median()\n",
    "m2 = p['Numero_Cilindros'].median()\n",
    "m3 = p['Potencia'].median()\n",
    "m4 = p['Capacidade_Motor'].median()\n",
    "\n",
    "p['Numero_Valvulas'].fillna(m, inplace=True)\n",
    "p['Numero_Cilindros'].fillna(m2, inplace=True)\n",
    "p['Potencia'].fillna(m3, inplace=True)\n",
    "p['Capacidade_Motor'].fillna(m4, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['clean_title'] = p['clean_title'].fillna('No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### novos atributos (derivações)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "p['T2'] = p['transmission'].str.extract(r'(\\d+)')\n",
    "p['T2'] = pd.to_numeric(p['T2'], errors='coerce')\n",
    "m5 = p['T2'].mean() \n",
    "p['T2'].fillna(round(m5), inplace=True)\n",
    "#p.head()\n",
    "#p['T2'].isnull().sum()\n",
    "# p['T2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria_ET (engine + transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = p[['Potencia', 'Capacidade_Motor', 'Numero_Cilindros', 'Numero_Valvulas', 'T2']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "n_clusters = 5\n",
    "\n",
    "# Aplicar o algoritmo K-means para agrupar os carros em clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Adicionar uma nova coluna 'Categoria' ao DataFrame com base nos clusters\n",
    "p['Categoria_ET'] = kmeans.labels_\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Contagem de amostras em cada categoria\n",
    "categoria_counts = p['Categoria_ET'].value_counts().sort_index()\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "plt.bar(categoria_counts.index, categoria_counts.values)\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "plt.xlabel('Categoria_ET')\n",
    "plt.ylabel('Número de amostras')\n",
    "plt.title('Distribuição das Categorias')\n",
    "\n",
    "#Mostrar o gráfico\n",
    "plt.show()\n",
    "\n",
    "p['Categoria_ET'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['Categoria_ET'] = p['Categoria_ET'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria Marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = p['brand'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência Marca'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência Marca'\n",
    "    else:\n",
    "        return 'Média Frequência Marca'\n",
    "\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "p['Categoria_Marca'] = p['brand'].map(frequencias.apply(categorizar))\n",
    "\n",
    "p['Categoria_Marca'] = p['Categoria_Marca'].astype('category')\n",
    "p['Categoria_Marca'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = p['model'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência Modelo'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência Modelo'\n",
    "    else:\n",
    "        return 'Média Frequência Modelo'\n",
    "\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "p['Categoria_Modelo'] = p['model'].map(frequencias.apply(categorizar))\n",
    "p['Categoria_Modelo'] = p['Categoria_Modelo'].astype('category')\n",
    "p['Categoria_Modelo'].value_counts()\n",
    "p['Categoria_Modelo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalidade das novas colunas (numéricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Lista das colunas numéricas que você deseja analisar\n",
    "colunas_numericas = ['Potencia', 'Capacidade_Motor', 'Numero_Cilindros',\n",
    "       'Numero_Valvulas', 'T2']\n",
    "\n",
    "num_colunas = len(colunas_numericas)\n",
    "fig, axs = plt.subplots(2, num_colunas, figsize=(15, 8))\n",
    "print(f'Teste de Shapiro-Wilk: \\n')\n",
    "\n",
    "# Iterar sobre as colunas numéricas e plotar os gráficos em cada subplot\n",
    "for i, coluna in enumerate(colunas_numericas):\n",
    "    # Histograma\n",
    "    sns.histplot(p[coluna], kde=True, ax=axs[0, i])\n",
    "    axs[0, i].set_title(f'{coluna}')\n",
    "    \n",
    "    # Gráfico QQ\n",
    "    stats.probplot(p[coluna], dist=\"norm\", plot=axs[1, i])\n",
    "    axs[1, i].set_title(f'QQ-plot')\n",
    " \n",
    "    # Teste de Shapiro-Wilk\n",
    "    stat, pv = stats.shapiro(p[coluna])\n",
    "    print(f'{coluna}:')\n",
    "    print(f'Valor p: {pv}')\n",
    "    if pv > 0.05:\n",
    "        print('Não podemos rejeitar a hipótese nula - A distribuição parece normal.')\n",
    "    else:\n",
    "        print('Rejeita-se a hipótese nula -> a distribuição não segue o modelo normal.')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como se pode observar, nenhum dos novos atributos (numéricos possuem distribuição normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Substituição de valores nulos e '-' PELA MODA\n",
    "- Remoção outliers LOF\n",
    "- Variavies cat -> numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL's substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['fuel_type'].unique()\n",
    "data1['fuel_type'].isnull().sum()\n",
    "data1['fuel_type'].fillna('Eletric', inplace=True)\n",
    "mod = data1['fuel_type'].mode()[0]\n",
    "\n",
    "data1['fuel_type'] = data1['fuel_type'].replace('–', mod)\n",
    "data1['fuel_type'].unique()\n",
    "\n",
    "mod1=data1['accident'].mode()[0]\n",
    "data1['accident'].fillna(mod1, inplace=True)\n",
    "\n",
    "mod3=data1['engine'].mode()[0]\n",
    "data1['engine'] = data1['engine'].replace('–', mod3)\n",
    "\n",
    "mod5=data1['ext_col'].mode()[0]\n",
    "data1['ext_col'] = data1['ext_col'].replace('–', mod5)\n",
    "\n",
    "mod6=data1['int_col'].mode()[0]\n",
    "data1['int_col'] = data1['int_col'].replace('–', mod6)\n",
    "\n",
    "mod7=data1['transmission'].mode()[0]\n",
    "data1['transmission'] = data1['transmission'].replace('–', mod6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria cor interna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data1['int_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência ext_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência ext_col'\n",
    "    elif limite_baixa < frequencia < limite_alta:  # Verifica se a frequência está entre os limites\n",
    "        return 'Média Frequência ext_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data1['Categoria_IntCol'] = data1['int_col'].map(frequencias.apply(categorizar))\n",
    "data1['Categoria_IntCol'] = data1['Categoria_IntCol'].astype('category')\n",
    "data1['Categoria_IntCol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['ext_col'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categoria cor externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data1['ext_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência ext_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência ext_col'\n",
    "    elif limite_baixa < frequencia < limite_alta:  # Verifica se a frequência está entre os limites\n",
    "        return 'Média Frequência ext_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data1['Categoria_ExtCol'] = data1['ext_col'].map(frequencias.apply(categorizar))\n",
    "data1['Categoria_ExtCol'] = data1['Categoria_ExtCol'].astype('category')\n",
    "data1['Categoria_ExtCol'].value_counts()\n",
    "data1['Categoria_ExtCol'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Selecionar apenas as variáveis numéricas\n",
    "numeric_df = data1.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calcular a correlação de Spearman\n",
    "spearman_corr = numeric_df.corr(method='spearman')\n",
    "\n",
    "# Visualizar a matriz de correlação de Spearman\n",
    "print(\"Matriz de correlação de Spearman:\")\n",
    "print(spearman_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#va's categóricas\n",
    "categorical_columns = data1.select_dtypes(include=['object','category']).columns\n",
    "correlations = {}\n",
    "for column in categorical_columns:\n",
    "    corr, _ = spearmanr(data1[column], data1['price'])\n",
    "    correlations[column] = corr\n",
    "\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier por IQR -> V.a Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices_dict = {}\n",
    "\n",
    "# Variáveis Numéricas\n",
    "for column in data1.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    Q1 = data1[column].quantile(0.25)\n",
    "    Q3 = data1[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    outlier_conditional = ((data1[column] > Q1 - 1.5*IQR) & (data1[column] < Q3 + 1.5*IQR))\n",
    "\n",
    "    outlier_indices_dict[column] = data1.loc[~outlier_conditional].index\n",
    "    \n",
    "    num_outliers = len(data1[~outlier_conditional])\n",
    "    print(f\"Número de outliers em '{column}': {num_outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### O número de válvulas têm muito pouca correlação com o preço -> N utiliza-se essa coluna para os cenários!\n",
    "###### Remove-se os 6 registros da capacidade do motor e os 57 com num de cilindros e 376 do T2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover registros com outliers (cujo correlação baixa com preço)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices_dict['Capacidade_Motor']\n",
    "outlier_indices_dict['Numero_Cilindros']\n",
    "outlier_indices_dict['T2']\n",
    "\n",
    "data1_s_out = data1.copy()\n",
    "\n",
    "outlier_indices_to_drop = outlier_indices_dict['Capacidade_Motor'].union(outlier_indices_dict['Numero_Cilindros']).union(outlier_indices_dict['T2'])\n",
    "data1_s_out.drop(outlier_indices_to_drop, inplace=True)\n",
    "\n",
    "# Verifica o tamanho do novo conjunto de dados\n",
    "print(\"Número de registros no novo conjunto de dados sem outliers:\", len(data1_s_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('subset_1.csv', index=False) # sem normalizar com outliers\n",
    "data1_s_out.to_csv('subset_1_s_out.csv', index=False) # sem normalizar sem outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  substituir '-' por desconhecido\n",
    "- Remoção outliers LOF\n",
    "- Variavies cat -> numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL's substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fuel_type'].unique()\n",
    "data2['fuel_type'].isnull().sum()\n",
    "data2['fuel_type'].fillna('Eletric', inplace=True)\n",
    "data2['fuel_type'] = data2['fuel_type'].replace('–', 'desconhecido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accident + engine + transmission + ex_col + int_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['accident'].fillna('desconhecido', inplace=True)\n",
    "data2['engine'] = data2['engine'].replace('–', 'desconhecido')\n",
    "data2['transmission'] = data2['transmission'].replace('–', 'desconhecido')\n",
    "data2['ext_col'] = data2['ext_col'].replace('–', 'desconhecido')\n",
    "data2['int_col'] = data2['int_col'].replace('–', 'desconhecido')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria cor interna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data2['int_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência int_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência int_col'\n",
    "    else:\n",
    "        return 'Média Frequência int_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data2['Categoria_IntCol'] = data2['int_col'].map(frequencias.apply(categorizar))\n",
    "data2['Categoria_IntCol'] = data2['Categoria_IntCol'].astype('category')\n",
    "data2['Categoria_IntCol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoria cor externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias = data2['ext_col'].value_counts()\n",
    "\n",
    "# Define os limites das categorias\n",
    "limite_alta = frequencias.quantile(0.75)\n",
    "limite_baixa = frequencias.quantile(0.25)\n",
    "\n",
    "# Função para atribuir categoria com base na frequência\n",
    "def categorizar(frequencia):\n",
    "    if frequencia >= limite_alta:\n",
    "        return 'Alta Frequência ext_col'\n",
    "    elif frequencia <= limite_baixa:\n",
    "        return 'Baixa Frequência ext_col'\n",
    "    else:\n",
    "        return 'Média Frequência ext_col'\n",
    "\n",
    "# Adiciona uma nova coluna 'categoria' ao DataFrame com as categorias das marcas\n",
    "data2['Categoria_ExtCol'] = data2['ext_col'].map(frequencias.apply(categorizar))\n",
    "data2['Categoria_ExtCol'] = data2['Categoria_ExtCol'].astype('category')\n",
    "data2['Categoria_ExtCol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Selecionar apenas as variáveis numéricas\n",
    "numeric_df = data2.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calcular a correlação de Spearman\n",
    "spearman_corr = numeric_df.corr(method='spearman')\n",
    "\n",
    "# Visualizar a matriz de correlação de Spearman\n",
    "print(\"Matriz de correlação de Spearman:\")\n",
    "print(spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#va categorica\n",
    "categorical_columns = data2.select_dtypes(include=['object','category']).columns\n",
    "correlations = {}\n",
    "for column in categorical_columns:\n",
    "    corr, _ = spearmanr(data2[column], data2['price'])\n",
    "    correlations[column] = corr\n",
    "\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier por IQR -> va.'s Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis Numéricas\n",
    "for column in data2.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    Q1 = data2[column].quantile(0.25)\n",
    "    Q3 = data2[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    outlier_conditional = ((data2[column] > Q1 - 1.5*IQR) & (data2[column] < Q3 + 1.5*IQR))\n",
    "    outlier_indices_dict[column] = data2.loc[~outlier_conditional].index\n",
    "    \n",
    "    num_outliers = len(data2[~outlier_conditional])\n",
    "    print(f\"Número de outliers em '{column}': {num_outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remover registros com outliers (cuja correlação baixa com preço)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices_dict['Capacidade_Motor']\n",
    "outlier_indices_dict['Numero_Cilindros']\n",
    "outlier_indices_dict['T2']\n",
    "\n",
    "data2_s_out = data2.copy()\n",
    "\n",
    "outlier_indices_to_drop = outlier_indices_dict['Capacidade_Motor'].union(outlier_indices_dict['Numero_Cilindros']).union(outlier_indices_dict['T2'])\n",
    "data2_s_out.drop(outlier_indices_to_drop, inplace=True)\n",
    "\n",
    "# Verifica o tamanho do novo conjunto de dados\n",
    "print(\"Número de registros no novo conjunto de dados sem outliers:\", len(data2_s_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('subset_2.csv', index=False) # sem normalizar com outliers\n",
    "data2_s_out.to_csv('subset_2_s_out.csv', index=False) # sem normalizar sem outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAÇÃO\n",
    "### Como subset 1 é muito parecido com subset 2, só vamos utilizar o subset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subset_1=pd.read_csv('subset_1.csv')\n",
    "subset_1_s_out=pd.read_csv('subset_1_s_out.csv')\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cenário 1 -> todas as variáveis (sem categorias extras (redundância))\n",
    "#### - (se for usar todas as variáveis não da para normalizar os dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### com outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = subset_1[['brand','model','model_year','milage','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title']]\n",
    "y1 = subset_1['price'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label logaritmizada (preço) + normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sem outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1out = subset_1_s_out[['brand','model','model_year','milage','fuel_type','engine','ext_col','int_col','accident','clean_title']] # tinha T2 » retirei...\n",
    "y1out = subset_1_s_out['price'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cenário 2 (todas as variáveis (categorias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### com outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = subset_1[['model_year', 'milage', 'fuel_type', 'accident', 'clean_title', 'Categoria_ET', 'Categoria_Marca', 'Categoria_Modelo', 'Categoria_IntCol', 'Categoria_ExtCol']]\n",
    "y2 = subset_1['price'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sem outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2out = subset_1_s_out[['model_year','milage','fuel_type','accident','clean_title','Categoria_ET','Categoria_Marca','Categoria_Modelo','Categoria_IntCol','Categoria_ExtCol']]  \n",
    "y2out = subset_1_s_out['price'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cenário 3 (ao olho, características do carro novo sem influência do condutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### com outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=subset_1[['Potencia','Capacidade_Motor','Numero_Cilindros','T2']]\n",
    "y3=subset_1['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sem outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3out = subset_1_s_out[['Potencia','Capacidade_Motor','Numero_Cilindros','T2']] \n",
    "y3out = subset_1_s_out['price'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cenário 4 (características do carro com influência do condutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### com outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=subset_1[['brand','model','model_year','milage','fuel_type','ext_col','int_col','accident','clean_title']]\n",
    "y4=subset_1['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sem outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4out = subset_1_s_out[['brand','model','model_year','milage','fuel_type','ext_col','int_col','accident','clean_title']]\n",
    "y4out = subset_1_s_out['price'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalização + label logaritmizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previsões para os cenários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar Data / Treinar e Avaliar Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "# from sklearn import datasets\n",
    "from slickml.metrics import (\n",
    "    RegressionMetrics,\n",
    ")  # downloaded from https://github.com/slickml/slick-ml # btw pip install slickml\n",
    "from matplotlib import pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
    ")\n",
    "\n",
    "# Definir o número de folds para a cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Função para calcular Mean Absolute Percentage Error\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Função para calcular REC AUC\n",
    "def rec_auc(y_true, y_pred):\n",
    "    # Calcula o erro normalizado\n",
    "    error = np.abs(y_true - y_pred) / np.abs(y_true)\n",
    "    # Ordena os erros\n",
    "    sorted_error = np.sort(error)\n",
    "    # Frequência cumulativa relativa\n",
    "    cumulative_freq = np.arange(1, len(sorted_error) + 1) / len(sorted_error)\n",
    "    # Calcula a AUC utilizando a regra do trapezoide\n",
    "    return np.trapz(cumulative_freq, sorted_error)\n",
    "\n",
    "# Função para calcular Coefficient of Variation\n",
    "def coefficient_of_variation(y_true, y_pred):\n",
    "    return np.std(y_pred) / np.mean(y_pred)\n",
    "\n",
    "# Função para calcular Mean of Variation\n",
    "def mean_of_variation(y_true, y_pred):\n",
    "    \n",
    "    return np.mean(y_pred) / np.mean(y_true)\n",
    "def calculate_rec_curve(y_true, y_pred):\n",
    "    error = np.abs(y_true - y_pred) / np.abs(y_true)\n",
    "    sorted_error = np.sort(error)\n",
    "    cumulative_freq = np.arange(1, len(sorted_error) + 1) / len(sorted_error)\n",
    "    return sorted_error, cumulative_freq\n",
    "\n",
    "# Função para plotar todas as curvas REC\n",
    "def plot_rec_curves(curves):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for model_id, (sorted_error, cumulative_freq) in curves.items():\n",
    "        plt.plot(sorted_error, cumulative_freq, label=f'Model {model_id}')\n",
    "    \n",
    "    plt.xlabel('Relative Error')\n",
    "    plt.ylabel('Cumulative Frequency')\n",
    "    plt.title('Curva REC')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def modelo (n,X,y):\n",
    "    # Listas para armazenar os resultados da validação cruzada\n",
    "    cv_r2_scores = []\n",
    "    cv_ev_scores = []\n",
    "    cv_mae_scores = []\n",
    "    cv_mse_scores = []\n",
    "    cv_msle_scores = []\n",
    "    cv_mape_scores = []\n",
    "    cv_rec_auc_scores = []\n",
    "    cv_coeff_var_scores = []\n",
    "    cv_mean_var_scores = []\n",
    "    c={}\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Dividir dados em treino e teste\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        features_num=X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "        features_cat=X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "        preprocessor = make_column_transformer(\n",
    "            (StandardScaler(), features_num),\n",
    "            (OneHotEncoder(handle_unknown=\"ignore\"), features_cat),\n",
    "            )\n",
    "        \n",
    "        # Aplicar preprocessamento\n",
    "        X_train_norm = preprocessor.fit_transform(X_train)\n",
    "        X_test_norm = preprocessor.transform(X_test)\n",
    "        \n",
    "        # Logaritmizar\n",
    "        y_train_log = np.log(y_train)\n",
    "        y_test_log = np.log(y_test)\n",
    "         \n",
    "        if n==1:\n",
    "            model=regressao_linear(X_train_norm,y_train_log)\n",
    "        elif n==2:\n",
    "            model=random_forest(X_train_norm,y_train_log)\n",
    "        elif n==3:\n",
    "            model=ada_boost(X_train_norm,y_train_log)\n",
    "        elif n==4:\n",
    "            model=decison_tree(X_train_norm,y_train_log)\n",
    "        else:\n",
    "            model=rn(X_train_norm,y_train_log,X_test_norm,y_test_log)\n",
    "            \n",
    "        if n == 5:\n",
    "            pred_log = model.predict(X_test_norm).flatten()\n",
    "        else:\n",
    "            pred_log = model.predict(X_test_norm)\n",
    "            \n",
    "        pred_orig_scale = np.exp(pred_log)\n",
    "\n",
    "        # p/ a curva rec\n",
    "        sorted_error, cumulative_freq = calculate_rec_curve(y_test, pred_orig_scale)\n",
    "        c[n] = (sorted_error, cumulative_freq)\n",
    "\n",
    "        # Calcular as métricas\n",
    "        r2 = r2_score(np.exp(y_test_log), pred_orig_scale)\n",
    "        ev = explained_variance_score(np.exp(y_test_log), pred_orig_scale)\n",
    "        mae = mean_absolute_error(np.exp(y_test_log), pred_orig_scale)\n",
    "        mse = mean_squared_error(np.exp(y_test_log), pred_orig_scale)\n",
    "        msle = mean_squared_log_error(np.exp(y_test_log), pred_orig_scale)\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_test_log), pred_orig_scale)\n",
    "        rec_auc_value = rec_auc(np.exp(y_test_log), pred_orig_scale)\n",
    "        #rec_curve = calculate_rec_curve(np.exp(y_test_log), pred_orig_scale)\n",
    "        coeff_var = coefficient_of_variation(np.exp(y_test_log), pred_orig_scale)\n",
    "        mean_var = mean_of_variation(np.exp(y_test_log), pred_orig_scale)\n",
    "        \n",
    "        # Armazenar as métricas\n",
    "        cv_r2_scores.append(r2)\n",
    "        cv_ev_scores.append(ev)\n",
    "        cv_mae_scores.append(mae)\n",
    "        cv_mse_scores.append(mse)\n",
    "        cv_msle_scores.append(msle)\n",
    "        cv_mape_scores.append(mape)\n",
    "        cv_rec_auc_scores.append(rec_auc_value)\n",
    "        cv_coeff_var_scores.append(coeff_var)\n",
    "        cv_mean_var_scores.append(mean_var)\n",
    "\n",
    "# Calcular as médias e desvios padrão das métricas\n",
    "    metrics = {\n",
    "        \"R2 Score\": (np.mean(cv_r2_scores), np.std(cv_r2_scores)),\n",
    "        \"Explained Variance Score\": (np.mean(cv_ev_scores), np.std(cv_ev_scores)),\n",
    "        \"Mean Absolute Error\": (np.mean(cv_mae_scores), np.std(cv_mae_scores)),\n",
    "        \"Mean Squared Error\": (np.mean(cv_mse_scores), np.std(cv_mse_scores)),\n",
    "        \"Mean Squared Log Error\": (np.mean(cv_msle_scores), np.std(cv_msle_scores)),\n",
    "        \"Mean Absolute Percentage Error\": (np.mean(cv_mape_scores), np.std(cv_mape_scores)),\n",
    "        \"REC AUC\": (np.mean(cv_rec_auc_scores), np.std(cv_rec_auc_scores)),\n",
    "        \"Coeff. of Variation\": (np.mean(cv_coeff_var_scores), np.std(cv_coeff_var_scores)),\n",
    "        \"Mean of Variation\": (np.mean(cv_mean_var_scores), np.std(cv_mean_var_scores))\n",
    "    }\n",
    "     \n",
    "    return c, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#cenario 1 -> com outlier\n",
    "def regressao_linear(X_train_norm,y_train_log):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_norm, y_train_log)\n",
    "    return model\n",
    "\n",
    "#modelo(1,X1,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cenario 1 -> com outlier\n",
    "def random_forest(X_train_norm,y_train_log):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train_norm,y_train_log)\n",
    "    return model\n",
    "#modelo(2,X1,y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cenario 1 -> com outliers \n",
    "def ada_boost(X_train_norm,y_train_log):\n",
    "    model = AdaBoostRegressor()\n",
    "    model.fit(X_train_norm,y_train_log)\n",
    "    return model\n",
    "#modelo(3,X1,y1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cenario 1 -> com outliers \n",
    "def decison_tree(X_train_norm,y_train_log):\n",
    "    model = tree.DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "    model.fit(X_train_norm,y_train_log)\n",
    "    return model\n",
    "#modelo(4,X1,y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropout + regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "# Cenario 1 -> com outliers \n",
    "def rn(X_train_norm,y_train_log,X_test_norm,y_test_log):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation='relu', input_dim=X_train_norm.shape[1]))\n",
    "    model.add(Dropout(0.3))  # Dropout para reduzir overfitting\n",
    "    model.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    model.fit(X_train_norm, y_train_log, epochs=50, batch_size=32, validation_data=(X_test_norm, y_test_log))\n",
    "    return model\n",
    "#modelo(5,X1,y1)\n",
    "\n",
    "#Plotando gráfico do histórico de treinamento\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(resultado.history['loss'])\n",
    "# plt.plot(resultado.history['val_loss'])\n",
    "# plt.title('Histórico de Treinamento')\n",
    "# plt.ylabel('Função de custo')\n",
    "# plt.xlabel('Épocas de treinamento')\n",
    "# plt.legend(['Erro treino', 'Erro teste'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### greedy search -> otimização de parâmetros RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Função para construir o modelo Keras\n",
    "def create_model(units1=64, units2=32, dropout_rate=0.5, kernel_regularizer=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units1, activation='relu', input_dim=X1_train_norm.shape[1]))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=units2, activation='relu', kernel_regularizer=regularizers.l2(kernel_regularizer)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Definindo os parâmetros a serem otimizados\n",
    "param_grid = {\n",
    "    'units1': [32, 64, 128],\n",
    "    'units2': [16, 32, 64],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'kernel_regularizer': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Realizando a pesquisa em grade\n",
    "grid_search_results = []\n",
    "\n",
    "for units1 in param_grid['units1']:\n",
    "    for units2 in param_grid['units2']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "            for kernel_regularizer in param_grid['kernel_regularizer']:\n",
    "                model = create_model(units1=units1, units2=units2, dropout_rate=dropout_rate, kernel_regularizer=kernel_regularizer)\n",
    "                history = model.fit(X1_train_norm, y1_train_log, epochs=100, batch_size=32, verbose=0, validation_split=0.2, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
    "                val_loss = history.history['val_loss'][-1]\n",
    "                grid_search_results.append({\n",
    "                    'units1': units1,\n",
    "                    'units2': units2,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'kernel_regularizer': kernel_regularizer,\n",
    "                    'val_loss': val_loss\n",
    "                })\n",
    "\n",
    "# Encontrando os melhores parâmetros\n",
    "best_params = min(grid_search_results, key=lambda x: x['val_loss'])\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(\"Melhores parâmetros encontrados: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cenário 1 -> Com Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 71.8818 - mae: 7.7638 - val_loss: 4.9208 - val_mae: 0.8130\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9920 - mae: 1.4666 - val_loss: 3.6469 - val_mae: 0.5984\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5629 - mae: 1.3234 - val_loss: 3.0207 - val_mae: 0.5482\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7389 - mae: 1.2290 - val_loss: 2.5149 - val_mae: 0.4642\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2655 - mae: 1.1978 - val_loss: 2.2753 - val_mae: 0.4963\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6491 - mae: 1.0786 - val_loss: 2.0777 - val_mae: 0.5172\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2880 - mae: 1.0549 - val_loss: 1.9098 - val_mae: 0.5228\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0748 - mae: 1.0356 - val_loss: 1.6778 - val_mae: 0.4718\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8289 - mae: 1.0154 - val_loss: 1.7427 - val_mae: 0.6186\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5017 - mae: 0.9494 - val_loss: 1.3391 - val_mae: 0.4069\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2997 - mae: 0.9143 - val_loss: 1.2947 - val_mae: 0.4522\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0566 - mae: 0.8706 - val_loss: 1.1709 - val_mae: 0.4174\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8743 - mae: 0.8380 - val_loss: 1.2049 - val_mae: 0.5063\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7060 - mae: 0.8001 - val_loss: 0.9720 - val_mae: 0.3974\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5438 - mae: 0.7578 - val_loss: 1.1201 - val_mae: 0.5419\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4009 - mae: 0.7227 - val_loss: 1.0066 - val_mae: 0.5074\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2643 - mae: 0.6880 - val_loss: 0.8669 - val_mae: 0.4407\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1381 - mae: 0.6545 - val_loss: 0.7794 - val_mae: 0.4127\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0648 - mae: 0.6420 - val_loss: 0.7476 - val_mae: 0.4235\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9659 - mae: 0.6080 - val_loss: 1.0453 - val_mae: 0.6617\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8952 - mae: 0.5931 - val_loss: 0.8844 - val_mae: 0.5764\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8275 - mae: 0.5656 - val_loss: 0.7595 - val_mae: 0.5074\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7037 - mae: 0.5252 - val_loss: 0.6464 - val_mae: 0.4420\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6345 - mae: 0.4928 - val_loss: 0.7962 - val_mae: 0.5754\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6221 - mae: 0.5000 - val_loss: 0.5665 - val_mae: 0.4199\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5492 - mae: 0.4668 - val_loss: 0.5580 - val_mae: 0.4320\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4816 - mae: 0.4386 - val_loss: 0.5396 - val_mae: 0.4263\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5114 - mae: 0.4597 - val_loss: 0.4762 - val_mae: 0.3970\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4784 - mae: 0.4558 - val_loss: 0.5630 - val_mae: 0.4622\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4347 - mae: 0.4233 - val_loss: 0.4440 - val_mae: 0.4033\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4432 - mae: 0.4490 - val_loss: 0.4488 - val_mae: 0.4048\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4217 - mae: 0.4384 - val_loss: 0.5663 - val_mae: 0.4893\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4120 - mae: 0.4385 - val_loss: 0.5298 - val_mae: 0.4712\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3886 - mae: 0.4251 - val_loss: 0.4086 - val_mae: 0.3990\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3969 - mae: 0.4395 - val_loss: 0.5326 - val_mae: 0.4812\n",
      "Epoch 36/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4155 - mae: 0.4337 - val_loss: 0.6636 - val_mae: 0.5747\n",
      "Epoch 37/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3842 - mae: 0.4275 - val_loss: 0.4207 - val_mae: 0.4061\n",
      "Epoch 38/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3606 - mae: 0.4176 - val_loss: 0.4600 - val_mae: 0.4371\n",
      "Epoch 39/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3360 - mae: 0.4057 - val_loss: 0.3769 - val_mae: 0.3983\n",
      "Epoch 40/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3456 - mae: 0.4164 - val_loss: 0.4386 - val_mae: 0.4310\n",
      "Epoch 41/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3151 - mae: 0.3978 - val_loss: 0.4209 - val_mae: 0.4171\n",
      "Epoch 42/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3545 - mae: 0.4228 - val_loss: 0.4113 - val_mae: 0.4136\n",
      "Epoch 43/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3188 - mae: 0.4049 - val_loss: 0.4397 - val_mae: 0.4373\n",
      "Epoch 44/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3268 - mae: 0.4120 - val_loss: 0.4633 - val_mae: 0.4613\n",
      "Epoch 45/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3290 - mae: 0.4114 - val_loss: 0.4901 - val_mae: 0.4797\n",
      "Epoch 46/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3036 - mae: 0.3964 - val_loss: 0.5475 - val_mae: 0.5243\n",
      "Epoch 47/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3324 - mae: 0.4153 - val_loss: 0.3874 - val_mae: 0.4072\n",
      "Epoch 48/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3170 - mae: 0.4001 - val_loss: 0.4758 - val_mae: 0.4736\n",
      "Epoch 49/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2994 - mae: 0.3959 - val_loss: 0.4969 - val_mae: 0.4879\n",
      "Epoch 50/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2975 - mae: 0.3882 - val_loss: 0.4893 - val_mae: 0.4793\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 89.2986 - mae: 8.9468 - val_loss: 5.2995 - val_mae: 0.8640\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9214 - mae: 1.6010 - val_loss: 3.9431 - val_mae: 0.5801\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4490 - mae: 1.4227 - val_loss: 3.2191 - val_mae: 0.4947\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3773 - mae: 1.3144 - val_loss: 2.7924 - val_mae: 0.5000\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8028 - mae: 1.2585 - val_loss: 2.3656 - val_mae: 0.4489\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0819 - mae: 1.1437 - val_loss: 2.0511 - val_mae: 0.4287\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6751 - mae: 1.1263 - val_loss: 1.8356 - val_mae: 0.4487\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2987 - mae: 1.0764 - val_loss: 1.5446 - val_mae: 0.3732\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0100 - mae: 1.0645 - val_loss: 1.4501 - val_mae: 0.4405\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7906 - mae: 1.0368 - val_loss: 1.2556 - val_mae: 0.3900\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5981 - mae: 1.0190 - val_loss: 1.2159 - val_mae: 0.4691\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2752 - mae: 0.9716 - val_loss: 0.9787 - val_mae: 0.3661\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0692 - mae: 0.9109 - val_loss: 0.9179 - val_mae: 0.3873\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9194 - mae: 0.9001 - val_loss: 0.8094 - val_mae: 0.3629\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7220 - mae: 0.8514 - val_loss: 0.7259 - val_mae: 0.3567\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6035 - mae: 0.8412 - val_loss: 0.6680 - val_mae: 0.3566\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4943 - mae: 0.8208 - val_loss: 0.6369 - val_mae: 0.3770\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3063 - mae: 0.7606 - val_loss: 0.5648 - val_mae: 0.3572\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2420 - mae: 0.7571 - val_loss: 0.5395 - val_mae: 0.3705\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1816 - mae: 0.7555 - val_loss: 0.4972 - val_mae: 0.3618\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0033 - mae: 0.6826 - val_loss: 0.4956 - val_mae: 0.4074\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9830 - mae: 0.6816 - val_loss: 0.4504 - val_mae: 0.3710\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9473 - mae: 0.6739 - val_loss: 0.4262 - val_mae: 0.3726\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7847 - mae: 0.6061 - val_loss: 0.3851 - val_mae: 0.3556\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7408 - mae: 0.5936 - val_loss: 0.3994 - val_mae: 0.3779\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7027 - mae: 0.5915 - val_loss: 0.3802 - val_mae: 0.3778\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6253 - mae: 0.5474 - val_loss: 0.3322 - val_mae: 0.3545\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5937 - mae: 0.5403 - val_loss: 0.3514 - val_mae: 0.3952\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5430 - mae: 0.5182 - val_loss: 0.3355 - val_mae: 0.3721\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5596 - mae: 0.5251 - val_loss: 0.3189 - val_mae: 0.3814\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4838 - mae: 0.4903 - val_loss: 0.2961 - val_mae: 0.3647\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4511 - mae: 0.4768 - val_loss: 0.2918 - val_mae: 0.3590\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4054 - mae: 0.4475 - val_loss: 0.3044 - val_mae: 0.3730\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4385 - mae: 0.4735 - val_loss: 0.2738 - val_mae: 0.3636\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3980 - mae: 0.4507 - val_loss: 0.2647 - val_mae: 0.3558\n",
      "Epoch 36/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3701 - mae: 0.4332 - val_loss: 0.2705 - val_mae: 0.3600\n",
      "Epoch 37/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3981 - mae: 0.4529 - val_loss: 0.2629 - val_mae: 0.3689\n",
      "Epoch 38/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3645 - mae: 0.4397 - val_loss: 0.2869 - val_mae: 0.3792\n",
      "Epoch 39/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3829 - mae: 0.4352 - val_loss: 0.2852 - val_mae: 0.3754\n",
      "Epoch 40/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3551 - mae: 0.4338 - val_loss: 0.2467 - val_mae: 0.3527\n",
      "Epoch 41/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3555 - mae: 0.4356 - val_loss: 0.2887 - val_mae: 0.4111\n",
      "Epoch 42/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3492 - mae: 0.4291 - val_loss: 0.2420 - val_mae: 0.3559\n",
      "Epoch 43/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3196 - mae: 0.4182 - val_loss: 0.2500 - val_mae: 0.3697\n",
      "Epoch 44/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3241 - mae: 0.4153 - val_loss: 0.2444 - val_mae: 0.3654\n",
      "Epoch 45/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3139 - mae: 0.4074 - val_loss: 0.2366 - val_mae: 0.3557\n",
      "Epoch 46/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3278 - mae: 0.4190 - val_loss: 0.2555 - val_mae: 0.3671\n",
      "Epoch 47/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3176 - mae: 0.4101 - val_loss: 0.2339 - val_mae: 0.3553\n",
      "Epoch 48/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3197 - mae: 0.4074 - val_loss: 0.2339 - val_mae: 0.3520\n",
      "Epoch 49/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2910 - mae: 0.3973 - val_loss: 0.2488 - val_mae: 0.3751\n",
      "Epoch 50/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3234 - mae: 0.4119 - val_loss: 0.2368 - val_mae: 0.3511\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 71.4394 - mae: 7.7656 - val_loss: 4.8596 - val_mae: 0.7616\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0264 - mae: 1.4578 - val_loss: 3.6161 - val_mae: 0.5537\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7995 - mae: 1.3527 - val_loss: 3.0805 - val_mae: 0.5867\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8134 - mae: 1.2449 - val_loss: 2.4717 - val_mae: 0.4444\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2587 - mae: 1.1901 - val_loss: 2.0949 - val_mae: 0.4309\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7355 - mae: 1.1177 - val_loss: 1.9452 - val_mae: 0.4775\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2582 - mae: 1.0632 - val_loss: 1.6491 - val_mae: 0.4168\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8641 - mae: 1.0036 - val_loss: 1.4708 - val_mae: 0.4072\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5681 - mae: 0.9697 - val_loss: 1.6522 - val_mae: 0.6514\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4324 - mae: 0.9659 - val_loss: 1.2240 - val_mae: 0.4272\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0876 - mae: 0.8753 - val_loss: 1.0615 - val_mae: 0.3985\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9677 - mae: 0.8783 - val_loss: 1.0229 - val_mae: 0.4213\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6908 - mae: 0.8141 - val_loss: 0.8700 - val_mae: 0.3893\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4506 - mae: 0.7456 - val_loss: 0.8186 - val_mae: 0.3955\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2945 - mae: 0.7016 - val_loss: 0.7231 - val_mae: 0.3929\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1234 - mae: 0.6604 - val_loss: 0.7009 - val_mae: 0.3987\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9994 - mae: 0.6203 - val_loss: 0.6429 - val_mae: 0.3931\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8962 - mae: 0.5840 - val_loss: 0.6387 - val_mae: 0.4197\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8735 - mae: 0.5961 - val_loss: 0.6661 - val_mae: 0.4650\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7752 - mae: 0.5770 - val_loss: 0.5000 - val_mae: 0.3983\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6244 - mae: 0.4981 - val_loss: 0.4798 - val_mae: 0.4193\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6114 - mae: 0.4899 - val_loss: 0.4993 - val_mae: 0.4140\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5224 - mae: 0.4648 - val_loss: 0.4401 - val_mae: 0.3904\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4898 - mae: 0.4581 - val_loss: 0.4011 - val_mae: 0.3928\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4637 - mae: 0.4475 - val_loss: 0.3867 - val_mae: 0.3981\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4318 - mae: 0.4384 - val_loss: 0.3768 - val_mae: 0.4150\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4556 - mae: 0.4601 - val_loss: 0.3624 - val_mae: 0.3919\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4054 - mae: 0.4308 - val_loss: 0.3492 - val_mae: 0.3988\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3746 - mae: 0.4228 - val_loss: 0.3438 - val_mae: 0.3912\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3752 - mae: 0.4326 - val_loss: 0.3471 - val_mae: 0.4272\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3725 - mae: 0.4236 - val_loss: 0.3719 - val_mae: 0.4635\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3689 - mae: 0.4324 - val_loss: 0.3131 - val_mae: 0.3935\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3586 - mae: 0.4210 - val_loss: 0.3109 - val_mae: 0.3835\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3201 - mae: 0.4119 - val_loss: 0.3174 - val_mae: 0.3881\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3238 - mae: 0.4052 - val_loss: 0.3001 - val_mae: 0.3854\n",
      "Epoch 36/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3099 - mae: 0.4001 - val_loss: 0.3395 - val_mae: 0.4041\n",
      "Epoch 37/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3287 - mae: 0.4163 - val_loss: 0.3030 - val_mae: 0.4020\n",
      "Epoch 38/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3002 - mae: 0.4018 - val_loss: 0.2899 - val_mae: 0.3985\n",
      "Epoch 39/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3212 - mae: 0.4024 - val_loss: 0.3044 - val_mae: 0.3897\n",
      "Epoch 40/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3276 - mae: 0.4129 - val_loss: 0.3034 - val_mae: 0.3863\n",
      "Epoch 41/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3185 - mae: 0.4171 - val_loss: 0.3104 - val_mae: 0.3928\n",
      "Epoch 42/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3156 - mae: 0.4087 - val_loss: 0.3082 - val_mae: 0.3896\n",
      "Epoch 43/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3219 - mae: 0.4241 - val_loss: 0.2834 - val_mae: 0.3812\n",
      "Epoch 44/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3011 - mae: 0.4049 - val_loss: 0.2863 - val_mae: 0.3868\n",
      "Epoch 45/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2946 - mae: 0.3959 - val_loss: 0.2950 - val_mae: 0.3868\n",
      "Epoch 46/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3200 - mae: 0.4037 - val_loss: 0.2815 - val_mae: 0.3969\n",
      "Epoch 47/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2808 - mae: 0.3886 - val_loss: 0.2741 - val_mae: 0.3803\n",
      "Epoch 48/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2919 - mae: 0.3952 - val_loss: 0.2814 - val_mae: 0.3993\n",
      "Epoch 49/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2914 - mae: 0.3961 - val_loss: 0.2935 - val_mae: 0.3823\n",
      "Epoch 50/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2845 - mae: 0.3973 - val_loss: 0.2801 - val_mae: 0.3984\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 76.6500 - mae: 8.1404 - val_loss: 4.9311 - val_mae: 0.8463\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9749 - mae: 1.4398 - val_loss: 3.6880 - val_mae: 0.6049\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6924 - mae: 1.3438 - val_loss: 3.0294 - val_mae: 0.5543\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7719 - mae: 1.2225 - val_loss: 2.4640 - val_mae: 0.4602\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1871 - mae: 1.1742 - val_loss: 2.1232 - val_mae: 0.4446\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6004 - mae: 1.0891 - val_loss: 1.8149 - val_mae: 0.4062\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1410 - mae: 1.0445 - val_loss: 1.6146 - val_mae: 0.4123\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7348 - mae: 0.9603 - val_loss: 1.3967 - val_mae: 0.3839\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6043 - mae: 0.9859 - val_loss: 1.3163 - val_mae: 0.4199\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3590 - mae: 0.9338 - val_loss: 1.1770 - val_mae: 0.4053\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2564 - mae: 0.9178 - val_loss: 1.0159 - val_mae: 0.3788\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8910 - mae: 0.8493 - val_loss: 0.9279 - val_mae: 0.3824\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7716 - mae: 0.8302 - val_loss: 0.8795 - val_mae: 0.3968\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6068 - mae: 0.7994 - val_loss: 0.8171 - val_mae: 0.4031\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3420 - mae: 0.7196 - val_loss: 0.7127 - val_mae: 0.3736\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1781 - mae: 0.6715 - val_loss: 0.6870 - val_mae: 0.3885\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0893 - mae: 0.6597 - val_loss: 0.6339 - val_mae: 0.4097\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9713 - mae: 0.6242 - val_loss: 0.7449 - val_mae: 0.5008\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9489 - mae: 0.6160 - val_loss: 0.5913 - val_mae: 0.4018\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7712 - mae: 0.5406 - val_loss: 0.5292 - val_mae: 0.3887\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7356 - mae: 0.5276 - val_loss: 0.5442 - val_mae: 0.4114\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6811 - mae: 0.5323 - val_loss: 0.4513 - val_mae: 0.3824\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6052 - mae: 0.4913 - val_loss: 0.4532 - val_mae: 0.3829\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5882 - mae: 0.4910 - val_loss: 0.4165 - val_mae: 0.3855\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5390 - mae: 0.4698 - val_loss: 0.3981 - val_mae: 0.3756\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5207 - mae: 0.4654 - val_loss: 0.3842 - val_mae: 0.3855\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4870 - mae: 0.4642 - val_loss: 0.5232 - val_mae: 0.4884\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4730 - mae: 0.4526 - val_loss: 0.3514 - val_mae: 0.3849\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4764 - mae: 0.4685 - val_loss: 0.3472 - val_mae: 0.3768\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4161 - mae: 0.4350 - val_loss: 0.3388 - val_mae: 0.3780\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4558 - mae: 0.4527 - val_loss: 0.4065 - val_mae: 0.4215\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4316 - mae: 0.4385 - val_loss: 0.3304 - val_mae: 0.3822\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4185 - mae: 0.4520 - val_loss: 0.3250 - val_mae: 0.3974\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3905 - mae: 0.4195 - val_loss: 0.3301 - val_mae: 0.3864\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3802 - mae: 0.4331 - val_loss: 0.3294 - val_mae: 0.3876\n",
      "Epoch 36/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3793 - mae: 0.4375 - val_loss: 0.2978 - val_mae: 0.3794\n",
      "Epoch 37/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3539 - mae: 0.4251 - val_loss: 0.3292 - val_mae: 0.3910\n",
      "Epoch 38/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3809 - mae: 0.4320 - val_loss: 0.2920 - val_mae: 0.3714\n",
      "Epoch 39/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3702 - mae: 0.4332 - val_loss: 0.2826 - val_mae: 0.3750\n",
      "Epoch 40/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3643 - mae: 0.4196 - val_loss: 0.2844 - val_mae: 0.3797\n",
      "Epoch 41/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3345 - mae: 0.4217 - val_loss: 0.2934 - val_mae: 0.3976\n",
      "Epoch 42/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3491 - mae: 0.4197 - val_loss: 0.2922 - val_mae: 0.3787\n",
      "Epoch 43/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3285 - mae: 0.4068 - val_loss: 0.2771 - val_mae: 0.3717\n",
      "Epoch 44/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3616 - mae: 0.4168 - val_loss: 0.2907 - val_mae: 0.3769\n",
      "Epoch 45/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3560 - mae: 0.4156 - val_loss: 0.2630 - val_mae: 0.3669\n",
      "Epoch 46/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3110 - mae: 0.4083 - val_loss: 0.2645 - val_mae: 0.3808\n",
      "Epoch 47/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3238 - mae: 0.4109 - val_loss: 0.2656 - val_mae: 0.3725\n",
      "Epoch 48/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3095 - mae: 0.3930 - val_loss: 0.2747 - val_mae: 0.3696\n",
      "Epoch 49/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2899 - mae: 0.3952 - val_loss: 0.3220 - val_mae: 0.4403\n",
      "Epoch 50/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3347 - mae: 0.4166 - val_loss: 0.3021 - val_mae: 0.4221\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 79.4895 - mae: 8.3629 - val_loss: 4.8478 - val_mae: 0.8125\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2621 - mae: 1.5359 - val_loss: 3.2287 - val_mae: 0.4990\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8529 - mae: 1.4293 - val_loss: 2.6526 - val_mae: 0.4915\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9365 - mae: 1.3439 - val_loss: 2.2990 - val_mae: 0.5098\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2228 - mae: 1.2232 - val_loss: 2.0341 - val_mae: 0.5193\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7622 - mae: 1.1748 - val_loss: 1.8550 - val_mae: 0.5504\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1556 - mae: 1.0607 - val_loss: 1.5702 - val_mae: 0.4695\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9971 - mae: 1.0787 - val_loss: 1.3996 - val_mae: 0.4474\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7462 - mae: 1.0468 - val_loss: 1.2092 - val_mae: 0.4094\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4601 - mae: 0.9892 - val_loss: 1.1096 - val_mae: 0.4067\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1417 - mae: 0.9187 - val_loss: 1.1384 - val_mae: 0.4986\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8755 - mae: 0.8455 - val_loss: 1.1051 - val_mae: 0.5345\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7237 - mae: 0.8182 - val_loss: 0.8519 - val_mae: 0.3868\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6004 - mae: 0.8110 - val_loss: 0.7786 - val_mae: 0.3765\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4153 - mae: 0.7524 - val_loss: 1.1152 - val_mae: 0.6682\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2891 - mae: 0.7096 - val_loss: 0.7874 - val_mae: 0.4593\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1565 - mae: 0.6764 - val_loss: 0.7280 - val_mae: 0.4500\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0228 - mae: 0.6203 - val_loss: 0.5942 - val_mae: 0.3773\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9549 - mae: 0.6191 - val_loss: 0.6542 - val_mae: 0.4490\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9344 - mae: 0.5992 - val_loss: 0.6263 - val_mae: 0.4496\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7790 - mae: 0.5434 - val_loss: 0.5605 - val_mae: 0.4158\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7255 - mae: 0.5221 - val_loss: 0.5010 - val_mae: 0.4020\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6901 - mae: 0.5161 - val_loss: 0.4796 - val_mae: 0.3926\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6451 - mae: 0.4999 - val_loss: 0.5049 - val_mae: 0.4280\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5485 - mae: 0.4591 - val_loss: 0.5492 - val_mae: 0.4706\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5660 - mae: 0.4797 - val_loss: 0.4222 - val_mae: 0.3926\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5227 - mae: 0.4582 - val_loss: 0.4027 - val_mae: 0.3860\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5359 - mae: 0.4827 - val_loss: 0.3938 - val_mae: 0.3914\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4980 - mae: 0.4722 - val_loss: 0.5016 - val_mae: 0.4780\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4691 - mae: 0.4497 - val_loss: 0.3657 - val_mae: 0.3866\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4524 - mae: 0.4505 - val_loss: 0.3647 - val_mae: 0.3895\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4425 - mae: 0.4349 - val_loss: 0.3767 - val_mae: 0.4080\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4445 - mae: 0.4450 - val_loss: 0.3635 - val_mae: 0.4014\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3759 - mae: 0.4115 - val_loss: 0.3455 - val_mae: 0.3942\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3772 - mae: 0.4130 - val_loss: 0.3970 - val_mae: 0.4391\n",
      "Epoch 36/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3926 - mae: 0.4298 - val_loss: 0.4121 - val_mae: 0.4536\n",
      "Epoch 37/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3985 - mae: 0.4330 - val_loss: 0.3138 - val_mae: 0.3806\n",
      "Epoch 38/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3448 - mae: 0.4057 - val_loss: 0.3217 - val_mae: 0.3915\n",
      "Epoch 39/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3673 - mae: 0.4096 - val_loss: 0.3095 - val_mae: 0.3831\n",
      "Epoch 40/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3214 - mae: 0.3888 - val_loss: 0.3004 - val_mae: 0.3763\n",
      "Epoch 41/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3675 - mae: 0.4200 - val_loss: 0.3253 - val_mae: 0.3967\n",
      "Epoch 42/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3559 - mae: 0.4115 - val_loss: 0.3130 - val_mae: 0.3912\n",
      "Epoch 43/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3366 - mae: 0.4125 - val_loss: 0.3008 - val_mae: 0.3896\n",
      "Epoch 44/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3113 - mae: 0.3911 - val_loss: 0.2956 - val_mae: 0.3833\n",
      "Epoch 45/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3176 - mae: 0.4008 - val_loss: 0.3647 - val_mae: 0.4354\n",
      "Epoch 46/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3082 - mae: 0.3963 - val_loss: 0.3141 - val_mae: 0.3976\n",
      "Epoch 47/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3358 - mae: 0.4083 - val_loss: 0.3258 - val_mae: 0.4071\n",
      "Epoch 48/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3148 - mae: 0.3945 - val_loss: 0.2859 - val_mae: 0.3806\n",
      "Epoch 49/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3254 - mae: 0.4078 - val_loss: 0.3608 - val_mae: 0.4370\n",
      "Epoch 50/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3114 - mae: 0.3993 - val_loss: 0.3082 - val_mae: 0.3994\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>Explained Variance Score</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean Squared Log Error</th>\n",
       "      <th>Mean Absolute Percentage Error</th>\n",
       "      <th>REC AUC</th>\n",
       "      <th>Coeff. of Variation</th>\n",
       "      <th>Mean of Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.18 +- 0.11</td>\n",
       "      <td>0.19 +- 0.12</td>\n",
       "      <td>19299.55 +- 3745.21</td>\n",
       "      <td>6462596928.35 +- 6986213242.39</td>\n",
       "      <td>0.28 +- 0.03</td>\n",
       "      <td>39.42 +- 1.29</td>\n",
       "      <td>3.22 +- 0.32</td>\n",
       "      <td>0.57 +- 0.01</td>\n",
       "      <td>0.81 +- 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.33 +- 0.16</td>\n",
       "      <td>0.33 +- 0.16</td>\n",
       "      <td>17169.76 +- 3331.03</td>\n",
       "      <td>5688091476.79 +- 6554549820.28</td>\n",
       "      <td>0.20 +- 0.02</td>\n",
       "      <td>34.65 +- 1.93</td>\n",
       "      <td>3.45 +- 1.21</td>\n",
       "      <td>0.79 +- 0.04</td>\n",
       "      <td>0.88 +- 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.25 +- 0.11</td>\n",
       "      <td>0.25 +- 0.11</td>\n",
       "      <td>21412.47 +- 3705.53</td>\n",
       "      <td>5981262954.17 +- 6621900028.11</td>\n",
       "      <td>0.27 +- 0.03</td>\n",
       "      <td>47.73 +- 2.32</td>\n",
       "      <td>4.33 +- 2.95</td>\n",
       "      <td>0.80 +- 0.06</td>\n",
       "      <td>0.99 +- 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.20 +- 0.11</td>\n",
       "      <td>0.22 +- 0.11</td>\n",
       "      <td>19963.24 +- 3648.97</td>\n",
       "      <td>6256575397.34 +- 6785388971.01</td>\n",
       "      <td>0.29 +- 0.02</td>\n",
       "      <td>43.03 +- 0.84</td>\n",
       "      <td>3.87 +- 0.77</td>\n",
       "      <td>0.61 +- 0.02</td>\n",
       "      <td>0.82 +- 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.17 +- 0.11</td>\n",
       "      <td>0.21 +- 0.11</td>\n",
       "      <td>20603.82 +- 4796.68</td>\n",
       "      <td>6517399074.33 +- 7216178826.12</td>\n",
       "      <td>0.30 +- 0.08</td>\n",
       "      <td>41.25 +- 6.93</td>\n",
       "      <td>3.31 +- 0.69</td>\n",
       "      <td>0.55 +- 0.05</td>\n",
       "      <td>0.78 +- 0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      R2 Score Explained Variance Score  \\\n",
       "0  Linear Regression  0.18 +- 0.11             0.19 +- 0.12   \n",
       "1      Random Forest  0.33 +- 0.16             0.33 +- 0.16   \n",
       "2           AdaBoost  0.25 +- 0.11             0.25 +- 0.11   \n",
       "3      Decision Tree  0.20 +- 0.11             0.22 +- 0.11   \n",
       "4     Neural Network  0.17 +- 0.11             0.21 +- 0.11   \n",
       "\n",
       "   Mean Absolute Error              Mean Squared Error Mean Squared Log Error  \\\n",
       "0  19299.55 +- 3745.21  6462596928.35 +- 6986213242.39           0.28 +- 0.03   \n",
       "1  17169.76 +- 3331.03  5688091476.79 +- 6554549820.28           0.20 +- 0.02   \n",
       "2  21412.47 +- 3705.53  5981262954.17 +- 6621900028.11           0.27 +- 0.03   \n",
       "3  19963.24 +- 3648.97  6256575397.34 +- 6785388971.01           0.29 +- 0.02   \n",
       "4  20603.82 +- 4796.68  6517399074.33 +- 7216178826.12           0.30 +- 0.08   \n",
       "\n",
       "  Mean Absolute Percentage Error       REC AUC Coeff. of Variation  \\\n",
       "0                  39.42 +- 1.29  3.22 +- 0.32        0.57 +- 0.01   \n",
       "1                  34.65 +- 1.93  3.45 +- 1.21        0.79 +- 0.04   \n",
       "2                  47.73 +- 2.32  4.33 +- 2.95        0.80 +- 0.06   \n",
       "3                  43.03 +- 0.84  3.87 +- 0.77        0.61 +- 0.02   \n",
       "4                  41.25 +- 6.93  3.31 +- 0.69        0.55 +- 0.05   \n",
       "\n",
       "  Mean of Variation  \n",
       "0      0.81 +- 0.06  \n",
       "1      0.88 +- 0.07  \n",
       "2      0.99 +- 0.06  \n",
       "3      0.82 +- 0.05  \n",
       "4      0.78 +- 0.19  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "c_rl,metrics_rl=modelo(1,X2,y2)\n",
    "c_rf,metrics_rf=modelo(2,X2,y2)\n",
    "c_ada,metrics_ada=modelo(3,X2,y2)\n",
    "c_dt,metrics_dt=modelo(4,X2,y2)\n",
    "c_rn,metrics_rn=modelo(5,X2,y2)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model\": [\"Linear Regression\", \"Random Forest\", \"AdaBoost\", \"Decision Tree\", \"Neural Network\"],\n",
    "    \"R2 Score\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"R2 Score\"][0], metrics_rl[\"R2 Score\"][1]),\n",
    "                 \"{:.2f} +- {:.2f}\".format(metrics_rf[\"R2 Score\"][0], metrics_rf[\"R2 Score\"][1]),\n",
    "                 \"{:.2f} +- {:.2f}\".format(metrics_ada[\"R2 Score\"][0], metrics_ada[\"R2 Score\"][1]),\n",
    "                 \"{:.2f} +- {:.2f}\".format(metrics_dt[\"R2 Score\"][0], metrics_dt[\"R2 Score\"][1]),\n",
    "                 \"{:.2f} +- {:.2f}\".format(metrics_rn[\"R2 Score\"][0], metrics_rn[\"R2 Score\"][1])],\n",
    "    \"Explained Variance Score\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Explained Variance Score\"][0], metrics_rl[\"Explained Variance Score\"][1]),\n",
    "                                  \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Explained Variance Score\"][0], metrics_rf[\"Explained Variance Score\"][1]),\n",
    "                                  \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Explained Variance Score\"][0], metrics_ada[\"Explained Variance Score\"][1]),\n",
    "                                  \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Explained Variance Score\"][0], metrics_dt[\"Explained Variance Score\"][1]),\n",
    "                                  \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Explained Variance Score\"][0], metrics_rn[\"Explained Variance Score\"][1])],\n",
    "    \"Mean Absolute Error\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Mean Absolute Error\"][0], metrics_rl[\"Mean Absolute Error\"][1]),\n",
    "                             \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Mean Absolute Error\"][0], metrics_rf[\"Mean Absolute Error\"][1]),\n",
    "                             \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Mean Absolute Error\"][0], metrics_ada[\"Mean Absolute Error\"][1]),\n",
    "                             \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Mean Absolute Error\"][0], metrics_dt[\"Mean Absolute Error\"][1]),\n",
    "                             \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Mean Absolute Error\"][0], metrics_rn[\"Mean Absolute Error\"][1])],\n",
    "    \"Mean Squared Error\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Mean Squared Error\"][0], metrics_rl[\"Mean Squared Error\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Mean Squared Error\"][0], metrics_rf[\"Mean Squared Error\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Mean Squared Error\"][0], metrics_ada[\"Mean Squared Error\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Mean Squared Error\"][0], metrics_dt[\"Mean Squared Error\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Mean Squared Error\"][0], metrics_rn[\"Mean Squared Error\"][1])],\n",
    "    \"Mean Squared Log Error\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Mean Squared Log Error\"][0], metrics_rl[\"Mean Squared Log Error\"][1]),\n",
    "                                \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Mean Squared Log Error\"][0], metrics_rf[\"Mean Squared Log Error\"][1]),\n",
    "                                \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Mean Squared Log Error\"][0], metrics_ada[\"Mean Squared Log Error\"][1]),\n",
    "                                \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Mean Squared Log Error\"][0], metrics_dt[\"Mean Squared Log Error\"][1]),\n",
    "                                \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Mean Squared Log Error\"][0], metrics_rn[\"Mean Squared Log Error\"][1])],\n",
    "    \"Mean Absolute Percentage Error\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Mean Absolute Percentage Error\"][0], metrics_rl[\"Mean Absolute Percentage Error\"][1]),\n",
    "                                        \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Mean Absolute Percentage Error\"][0], metrics_rf[\"Mean Absolute Percentage Error\"][1]),\n",
    "                                        \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Mean Absolute Percentage Error\"][0], metrics_ada[\"Mean Absolute Percentage Error\"][1]),\n",
    "                                        \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Mean Absolute Percentage Error\"][0], metrics_dt[\"Mean Absolute Percentage Error\"][1]),\n",
    "                                        \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Mean Absolute Percentage Error\"][0], metrics_rn[\"Mean Absolute Percentage Error\"][1])],\n",
    "    \"REC AUC\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"REC AUC\"][0], metrics_rl[\"REC AUC\"][1]),\n",
    "                \"{:.2f} +- {:.2f}\".format(metrics_rf[\"REC AUC\"][0], metrics_rf[\"REC AUC\"][1]),\n",
    "                \"{:.2f} +- {:.2f}\".format(metrics_ada[\"REC AUC\"][0], metrics_ada[\"REC AUC\"][1]),\n",
    "                \"{:.2f} +- {:.2f}\".format(metrics_dt[\"REC AUC\"][0], metrics_dt[\"REC AUC\"][1]),\n",
    "                \"{:.2f} +- {:.2f}\".format(metrics_rn[\"REC AUC\"][0], metrics_rn[\"REC AUC\"][1])],\n",
    "    \"Coeff. of Variation\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Coeff. of Variation\"][0], metrics_rl[\"Coeff. of Variation\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Coeff. of Variation\"][0], metrics_rf[\"Coeff. of Variation\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Coeff. of Variation\"][0], metrics_ada[\"Coeff. of Variation\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Coeff. of Variation\"][0], metrics_dt[\"Coeff. of Variation\"][1]),\n",
    "                            \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Coeff. of Variation\"][0], metrics_rn[\"Coeff. of Variation\"][1])],\n",
    "    \"Mean of Variation\": [\"{:.2f} +- {:.2f}\".format(metrics_rl[\"Mean of Variation\"][0], metrics_rl[\"Mean of Variation\"][1]),\n",
    "                          \"{:.2f} +- {:.2f}\".format(metrics_rf[\"Mean of Variation\"][0], metrics_rf[\"Mean of Variation\"][1]),\n",
    "                          \"{:.2f} +- {:.2f}\".format(metrics_ada[\"Mean of Variation\"][0], metrics_ada[\"Mean of Variation\"][1]),\n",
    "                          \"{:.2f} +- {:.2f}\".format(metrics_dt[\"Mean of Variation\"][0], metrics_dt[\"Mean of Variation\"][1]),\n",
    "                          \"{:.2f} +- {:.2f}\".format(metrics_rn[\"Mean of Variation\"][0], metrics_rn[\"Mean of Variation\"][1])]})\n",
    "\n",
    "all_curves = {**c_rl, **c_rf, **c_ada, **c_dt, **c_rn}\n",
    "\n",
    "# Plotar todas as curvas REC\n",
    "plot_rec_curves(all_curves)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample ( apenas nos dados de treino )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversample cenário 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c/outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = subset_1['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "bins = [0, 10000, 30000, 60000, 100000, float('inf')]\n",
    "labels = ['Muito Baixo', 'Baixo', 'Médio', 'Alto', 'Luxo']\n",
    "y1 = pd.cut(y1, bins=bins, labels=labels)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "#Normalização\n",
    "features_num = X1.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "features_cat = X1.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), features_num),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), features_cat),\n",
    ")\n",
    "X1_train_norm = preprocessor.fit_transform(X1_train)\n",
    "X1_test_norm = preprocessor.transform(X1_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X1_train_smote, y1_train_smote = smote.fit_resample(X1_train_norm, y1_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X1_train_smote, y1_train_smote)\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "y1_pred = svm_model.predict(X1_test_norm)\n",
    "\n",
    "print(classification_report(y1_test, y1_pred))\n",
    "cm=confusion_matrix(y1_test, y1_pred)\n",
    "# matriz de confusão \n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y1_test_binarized = label_binarize(y1_test, classes=np.unique(y1_test))\n",
    "y1_pred_binarized = label_binarize(y1_pred, classes=np.unique(y1_test))\n",
    "\n",
    "# Número de classes\n",
    "n_classes = y1_test_binarized.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculando a curva ROC e a área sob a curva para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y1_test_binarized[:, i], y1_pred_binarized[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotando a curva ROC para cada classe\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(labels)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for {labels[i]}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha de não discriminação\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decison Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# cenário 1\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X1_train_smote, y1_train_smote)\n",
    "y_pred = clf.predict(X1_test_norm)\n",
    "\n",
    "print(classification_report(y1_test, y_pred))\n",
    "cm=confusion_matrix(y1_test, y_pred)\n",
    "# matriz de confusão \n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,10)) # árvore\n",
    "# plot_tree(clf, feature_names=preprocessor.get_feature_names_out(), class_names=labels, filled=True, rounded=True, fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Probabilidades previstas para cada classe\n",
    "y_score = clf.predict_proba(X1_test_norm)\n",
    "\n",
    "# Binarizando as classes\n",
    "y_test_bin = label_binarize(y1_test, classes=labels)\n",
    "\n",
    "# Calculando a curva ROC e a área sob a curva para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotando a curva ROC para cada classe\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(labels)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for {labels[i]}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha de não discriminação\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "\n",
    "logistic_model.fit(X1_train_smote, y1_train_smote)\n",
    "\n",
    "y1_pred_logistic = logistic_model.predict(X1_test_norm)\n",
    "\n",
    "print(classification_report(y1_test, y1_pred_logistic))\n",
    "cm=confusion_matrix(y1_test, y1_pred_logistic)\n",
    "# matriz de confusão \n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Probabilidades previstas para cada classe\n",
    "y_score = logistic_model.predict_proba(X1_test_norm)\n",
    "\n",
    "# Binarizando as classes\n",
    "y_test_bin = label_binarize(y1_test, classes=labels)\n",
    "\n",
    "# Calculando a curva ROC e a área sob a curva para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotando a curva ROC para cada classe\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(labels)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for {labels[i]}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha de não discriminação\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net - classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# transformação numerica\n",
    "le = LabelEncoder()\n",
    "y1_train_smote_num = le.fit_transform(y1_train_smote)\n",
    "y1_test_num = le.transform(y1_test)\n",
    "\n",
    "#vetores binarios\n",
    "y1_train_smote_cat = to_categorical(y1_train_smote_num)\n",
    "y1_test_cat = to_categorical(y1_test_num)\n",
    "\n",
    "# O mesmo que em regressão\n",
    "def create_nn_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))  # Para classificação multiclasse\n",
    "    return model\n",
    "\n",
    "input_dim = X1_train_smote.shape[1]\n",
    "output_dim = y1_train_smote_cat.shape[1]\n",
    "\n",
    "nn_model = create_nn_model(input_dim, output_dim)\n",
    "nn_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "nn_model.fit(X1_train_smote, y1_train_smote_cat, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y1_pred_nn = nn_model.predict(X1_test_norm)\n",
    "y1_pred_nn_labels = np.argmax(y1_pred_nn, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_test_num, y1_pred_nn_labels, target_names=le.classes_))\n",
    "cm = confusion_matrix(y1_test_num, y1_pred_nn_labels)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a curva ROC e AUC para cada classe\n",
    "from itertools import cycle\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y1_test_cat.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y1_test_cat[:, i], y1_pred_nn[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calcular a curva ROC média (macro)\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plotar todas as curvas ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha de não discriminação\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'blue', 'yellow', 'pink'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC classe {le.classes_[i]} (área = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], color='navy', linestyle=':', linewidth=4, label=f'ROC média (macro) (área = {roc_auc[\"macro\"]:.2f})')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC para cada classe')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "ada_clf.fit(X1_train_smote, y1_train_smote)\n",
    "\n",
    "y_pred_ada = ada_clf.predict(X1_test_norm)\n",
    "\n",
    "print(classification_report(y1_test, y_pred_ada))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm_ada = confusion_matrix(y1_test, y_pred_ada)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm_ada, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão do AdaBoost')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Probabilidades previstas para cada classe\n",
    "y_score = ada_clf.predict_proba(X1_test_norm)\n",
    "\n",
    "# Binarizando as classes\n",
    "y_test_bin = label_binarize(y1_test, classes=labels)\n",
    "\n",
    "# Calculando a curva ROC e a área sob a curva para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotando a curva ROC para cada classe\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(labels)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for {labels[i]}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha de não discriminação\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
